%************************************************
\chapter{Algoritmos}\label{ch:algoritmos}
%************************************************

En este capítulo se tratarán los diferentes algoritmos considerados en el trabajo, desde su
fundamento teórico hasta su implementación concreta.

Antes de describir cada algoritmo, vamos a ver consideraciones más generales sobre ellos y sobre el problema.
% Representación de la solución. Inicialización del programa (lectura). Operador vecino. Entorno. Función objetivo.

Cada solución del problema será un clique que se encuentre dentro del grafo. Este clique estará representado
por los nodos que contiene, de forma que las soluciones serán \textit{arrays} de la forma $[x_0, \dots, x_p]$.

La función para medir la calidad de una solución (función objetivo) será el tamaño de cada clique, si bien
se considerarán algunas variantes en ciertos algoritmos. No obstante, como el objetivo final el obtener un clique
del mayor tamaño posible, es lógico que el factor de peso en cualquier función objetivo sea el tamaño del mismo.

Como operador de vecino tenemos tres distintos, que juntos, aplicados sobre el clique, nos permitirán obtener
su entorno. El primero de ellos, al que llamaremos operador \textit{add}, consiste en añadir al clique un
nuevo nodo que conserve la estructura de clique, esto es, que esté conectado con todos los nodos del clique.
Usualmente tendremos calculado el conjunto de nodos que podemos añadir a cada clique, al que llamaremos $C_0$ o
posibles adiciones.

El segundo operador, al que nos referiremos como \textit{swap}, consiste en intercambiar un nodo del clique con uno de
fuera, de forma que se siga manteniendo la estructura. Para ello, el nodo que no pertenece al clique debe estar
conectado con todos salvo uno de sus nodos, que será el nodo que saldrá del clique. Nos referiremos a
este conjunto de nodos como posibles intercambios o $C_1$. Al igual que el anterior, también tendremos calculado
dicho conjunto de nodos para cada clique.

Finalmente, el tercer operador de vecino será el operador \textit{drop}, que consiste simplemente en quitar un nodo
del clique. Es claro que se mantiene la estructura de clique al aplicar este operador.

Estos serán los tres operadores que utilicemos, que definirán el entorno de una solución, compuesto por
aquellas a las que se puede llegar mediante el uso de cualquiera de los tres. No obstante, no siempre se
usarán los tres a la vez. El operador \textit{add} es esencial, pues nos permite ampliar el tamaño de un clique,
por lo que siempre lo utilizaremos. Los otros dos operadores se usarán dependiendo del algoritmo, siendo el operador
\textit{swap} bastante frecuente, y el \textit{drop} menos frecuente. Debido a esto, el entorno variará dependiendo de
aquellos consideramos. Detallaremos en cada caso los operadores considerados y las razones principales.

\section{Inicialización del programa}
Lo primero que hay que resolver es la lectura de los archivos y la creación de las estructuras de datos correspondientes
para cada grafo. Para ello, se ha creado el archivo \textit{reader.rb}, que contiene el método de lectura de los archivos.
Cada uno de ellos dará lugar a un objeto de la clase \textbf{Problem}, que almacena el número de vértices, el número de
arcos, la matriz de adyacencia y el nombre del archivo del que proviene el grafo.

Para la lectura, simplemente recorreremos el directorio en el que están almacenados los archivos, y generaremos un problema
por cada uno de ellos, marcando en la matriz de adyacencia los arcos que están conectados. Almacenaremos el conjunto de problemas
en una variable, para tenerlos disponibles a la hora de aplicarles los algoritmos.

\section{Algoritmos \textit{greedy}}

Los algoritmos voraces, o algoritmos \textit{greedy}, son aquellos que resuelven problemas tomando
las decisiones óptimas en cada instante. Esto no lleva necesariamente a un óptimo global, pero puede
aproximarlo de forma razonable en un periodo de tiempo generalmente muy pequeño. Este tipo de algoritmos
basan sus decisiones en las decisiones que ya se han tomado, pero nunca en lo que podría suceder más
adelante.

Por lo general, en los algoritmos \textit{greedy} tendremos un conjunto de candidatos, una función
de selección, que se encarga de elegir al mejor candidato en cada momento, una función objetivo, que
da un valor a cada solución, una función de factibilidad, que elige los candidatos que se pueden incluir
en una solución, y una función que nos dice si tenemos una solución.

Este tipo de algoritmos suelen ser irreversibles, esto es, no se pueden deshacer elecciones ya hechas.
No obstante, existen varios tipos de algoritmos \textit{greedy}, en los que esta condición se relaja. Así,
distinguiremos entre algoritmos \textit{greedy} puros, relajados y ortogonales. En este trabajo se han
considerado únicamente los primeros.

\subsection{\textit{Greedy} en MCP}

En el problema del clique máximo, los algoritmos \textit{greedy} tienen dos enfoque principales:
o bien se parte de un conjunto vacío y se añaden vértices, respetando la estructura de clique,
hasta que no sea posible añadir más, o partimos del conjunto total de vértices y vamos eliminando
hasta que el obtenido sea un clique.

Los dos algoritmos \textit{greedy} que he implementado siguen el primer enfoque de los mencionados anteriormente.
Se diferencian principalmente en la elección del vértice que se añade al clique, aunque en uno de ellos modificaremos
también la estructura de entornos, considerando intercambios además de adiciones.

A continuación, se detallan en más profundidad los dos algoritmos implementados:

\subsection{Primer algoritmo}

Este algoritmo es el enfoque más básico posible dentro de los algoritmos voraces para MCP.
Comenzando desde un clique vacío, añade elementos al clique, respetando la estructura, hasta
que no se pueda añadir ninguno más. Para elegir el vértice que añadir, toma, de aquellos que
pueden añadirse, el que tiene mayor número de adyacencias globales, usando el operador \textit{add}.
Otras posibles opciones serían elegir un nodo aleatorio entre los disponibles o tomar aquel que
maximice el tamaño del conjunto $C_0$ al añadirse al clique.

Vemos a continuación el pseudocódigo del algoritmo.

\begin{algorithm}[H]
\caption{Greedy}
  \begin{algorithmic}
  \State $Clique = [ ]$
  \State $C_0 = $ Vértices
  \Repeat
    \State{Añadir $v \in C_0$ con más adyacencias}
    \State{Actualizar $C_0$}
  \Until{$C_0 = \emptyset$}
  \State{Devolver clique}
  \end{algorithmic}
\end{algorithm}


\subsection{Segundo algoritmo}

En este algoritmo, se han seguido las ideas de Grosso, Locatelli y Della Croce, usando un algoritmo
que nos permite deshacer, en cierta forma, decisiones tomadas anteriormente. La idea es no solo
considerar aquellos vértices que pueden ser añadidos al clique, sino también tomar aquellos que
pueden ser intercambiados por uno del clique, es decir, usar operadores \textit{add} y \textit{swap}.

El criterio para elegir un nodo será el número de conexiones con el conjunto de posibles adiciones
al clique, buscando maximizar este número. Así, tendremos un mayor número de posibles adiciones, que
representan una cota superior para el tamaño del clique, pues este no puede ampliar su tamaño
más que el tamaño de la lista de posibles adiciones.

Antes de considerar intercambios, queremos que el clique tenga un tamaño mínimo. Se ha fijado
dicho tamaño en $4$, valor a partir del cual se empiezan a considerar los intercambios y no
solo las adiciones. Como criterio de parada, se ha establecido un número de intercambios máximo,
además de comprobar siempre que el entorno no sea vacío. Una vez satisfecha alguna de estas
condiciones, el clique que tengamos será ampliado hasta su límite usando movimientos \textit{add},
finalizando cuando no sea posible añadir más nodos.

Para evitar swaps inútiles, en caso de intercambiar dos nodos guardaremos el que
sale del clique, para no tenerlo en cuenta en la siguiente iteración. De no hacer esto, cabe la
posibilidad de entrar en un bucle, en el que se intercambien dos nodos de forma indefinida
hasta que se alcance el criterio de parada.

Vemos a continuación el pseudocódigo de la parte adaptativa del algoritmo.


\begin{algorithm}[H]
\caption{Greedy adaptativo}
  \begin{algorithmic}
  \State $Clique = [ ]$
  \State $C_0 = $ Vértices
  \State $C_1 = [ ]$
  \State $i = 0$
  \Repeat
    \State Tomar $v \in C_0 \cup C_1 - Swap$ que maximice adyacencias con $C_0$
    \If {$v \in C_0$}
      \State Añadir $v$ a $Clique$
    \Else
      \State Hacer intercambio
      \State Actualizar $Swap$, $i += 1$
    \EndIf
    \State{Actualizar $C_0, C_1$}
  \Until{$C_0 = \emptyset$ o $i = limite$}
  \State{Devolver clique}
  \end{algorithmic}
\end{algorithm}


\section{Búsqueda local}

Los algoritmos de búsqueda local son aquellos que se centran en el entorno de una solución
para buscar nuevas soluciones que sean mejores que la anterior. Dentro del espacio de soluciones,
cada solución tendrá un entorno compuesto por sus soluciones vecinas, que serán las que exploremos
sucesivamente.

Las técnicas de búsqueda local se utilizan no solo como heurísticas para resolver problemas,
sino como complementos de otras. Por ejemplo, pueden ser utilizadas junto a los algoritmos genéticos
para mejorar el conjunto de soluciones, o aplicarse después de técnicas \textit{greedy} para explorar
el espacio de soluciones. También se usan en técnicas multiarranque como ILS o GRASP, que explicaremos
más adelante.

En los algoritmos de búsqueda local podemos permitir ciertos comportamientos que darán lugar a
distintos algoritmos. La búsqueda local básica busca mejorar el resultado con un elemento del
entorno, terminando si este no existe y alcanzando un máximo local. Si queremos permitir que
las soluciones puedan ser peores, existen algoritmos como el enfriamiento simulado o la búsqueda
tabú. En cuando a la estructura de entornos, también puede ser variable, lo que nos llevaría
a una búsqueda en entornos variables o, nuevamente, a una búsqueda tabú. Todo esto se hace con
el objetivo de que nuestro algoritmo sea capaz de escapar de óptimos locales, y alcance el
óptimo global.

En este trabajo, se han implementado dos técnicas de búsqueda local, que difieren en la estructura de
entornos y en el método de elección de candidatos. Asimismo, se ha implementado un algoritmo de
enfriamiento simulado, y se han incorporado varias de las técnicas mencionadas anteriormente en
otros algoritmos. Estas serán mencionadas y detalladas en cada uno de ellos.

\subsection{Búsqueda local en MCP}

En la búsqueda local, las diferencias que hacen a los algortimos distintos están en la estructura
de entornos y en la elección de la solución vecina a la que desplazarse. Estas diferencias son también
las que existen entre los dos algoritmos implementados en este trabajo.

En el primer algoritmo se consideran movimientos \textit{add}, \textit{swap} y también \textit{drop}.
Si bien esto rompe con la filosofía de que la búsqueda local debe ir a mejores soluciones, la posibilidad de
eliminar elementos del clique se incluye para evitar que estos algoritmos sean similares a los
\textit{greedy}.

En el segundo algoritmo, solo se consideran movimientos \textit{add} y \textit{swap}. Si bien puede
parecer similar al algoritmo \textit{greedy} adaptativo detallado anteriormente, tiene varias diferencias
fundamentales con respecto a este.

Veámoslos en más detalles.

\subsection{Primer algoritmo}

Este algoritmo se basa en las ideas de Katayama, Hamamoto y Narihisa. En él, se han considerado
los tres movimientos básicos de la búsqueda local, \textit{add, swap} y \textit{drop},
dando distintas prioridades a cada uno de ellos. Como nuestro objetivo es construir un clique del
mayor tamaño posible, añadiremos vértices siempre que podamos, tomando aquel que tenga más conexiones
con el conjunto $C_0$ en caso de haber varios. Cuando no sea posible, intentaremos
hacer un swap, siempre que este nos lleve a un escenario en el que podamos añadir más nodos
al clique resultante. La elección de los nodos a intercambiar se hace mediante la técnica del
primer mejor, esto es, tomamos el primero que encontremos. De no poder hacer ningún swap bajo
estas condiciones, eliminaremos del clique el nodo que tenga menos adyacencias con todos los nodos del grafo.

Para evitar que los nodos que eliminemos sean añadidos inmediatamente al clique,
los iremos acumulando en una lista tabú, que será reiniciada a una lista vacía al hacer
un nuevo movimiento add, que involucrará un nodo distinto de los nodos tabú. Así, nos aseguramos
que el clique cambia, y no entramos en un bucle. Esta lista tabú será vaciada en el momento en el
que se realice un movimiento que no sea quitar un nodo del clique.

Como este algoritmo no tiene un criterio de parada inducido por el entorno, pues siempre podremos
hacer alguno de los tres movimientos. Es necesario establecer un límite, que este caso, ha
sido establecer un número de swaps y drops a realizar a lo largo del algoritmo. Una vez alcanzado
este número, el algoritmo finaliza, devolviendo el mejor clique encontrado.
Para evitar que el límite sea una constante común para todas las instancias, se ha establecido en proporción
al número de vértices del grafo.

El hecho de considerar un criterio de elección sobre los nodos del conjunto $C_0$ y $C_1$ hace que
el orden del algoritmo sea $\mathcal{O}(nl)$, donde $n$ el el tamaño del grafo y $l$ el límite impuesto.

Este algoritmo puede trabajar partiendo desde cualquier clique, lo que nos permite utilizarlo en técnicas
híbridas como algoritmos meméticos, o para mejorar cualquier solución ya existente. Para evaluar
sus prestaciones por separado, partirá desde un clique vacío, que es equivalente a pasarle una solución
inicial construída con un algoritmo \textit{greedy} que añada nodos utilizando el mismo criterio que esta
búsqueda local.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{Búsqueda local 1}
  \begin{algorithmic}
    \State $i = 0$
    \State $Tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If {$C_0$ no es vacío}
        \State Añadir el nodo de $C_0$ que tenga más conexiones con $C_0$.
        \State $Tabu = \emptyset$
      \Else
        \State Buscar en $C_1$ el primer intercambio que nos da un $C_0$ no vacío.
        \If {El intercambio existe}
          \State Hacer intercambio
          \State $Tabu = \emptyset$
          \State $i = i + 1$
        \Else
          \State Quitar el nodo del clique con más adyacencias en el grafo.
          \State Añadirlo a $Tabu$.
          \State $i = i + 1$
        \EndIf
      \EndIf
      \State{Actualizar $C_0, C_1$, teniendo en cuenta $Tabu$.}
    \Until{$i = limite$}
    \State{Devolver mejor clique encontrado}
  \end{algorithmic}
\end{algorithm}

\subsection{Segundo algoritmo}

Este algoritmo está basado en la búsqueda local dinámica o DLS (del inglés, \textit{Dynamic Local Search},
propuesta por W. Pullan y H. Hoos en el año 2006, y en concreto, se basa en una adaptación hecha
por () para un algoritmo de búsqueda local iterada, que veremos más adelante.
Sigue una filosofía más simple que el anterior pues solo considera movimientos \textit{add}
y \textit{swap}, a los que volveremos a ordenar por prioridad. Además, incluye una lista
tabú con los nodos que han salido del clique mediante un swap. Limitaremos la longitud de esta
lista a un 2\% del número de vértices en el grafo, para que no aloje un gran número de nodos.

Nuestro entorno consistirá en el conjunto de posibles adiciones ($C_0$) y el conjunto de
posibles intercambios ($C_1$), al que quitaremos la lista tabú. Como teóricamente, el entorno
puede ser vacío, si se diera el caso el algoritmo finalizaría. No obstante, se ha establecido un
límite de intercambios, pues en la práctica no tiene por qué suceder.

La prioridad entre movimientos es la siguiente: primero intentaremos añadir un elemento de
$C_0$ que no esté en la lista tabú, comprobando si existe alguno, y tomando uno aleatorio
en caso de existir varios. De no existir ninguno, tomaremos el conjunto $C_1$ quitando
la lista tabú, y, si existe algún elemento que lo cumpla, no es vacío, haremos el intercambio,
que volverá a ser aleatorio si teneos varios candidatos. Dicho nodo será añadido a la lista tabú.
Finalmente, en caso de que este conjunto también fuera vacío, solo nos queda la posibilidad de añadir un
elemento de la lista tabú que esté en $C_0$. Nuevamente, elegiremos uno aleatorio entre los existentes.
Como en el anterior, devolveremos el mejor clique que haya encontrado el algoritmo.

Como en este caso la elección de nodos es aleatoria, se considera un único bucle,
luego la complejidad de este algoritmo es lineal sobre el límite establecido,
$\mathcal{O}(l)$. Debido a esto, ofrecerá mejores tiempos de cómputo que el otro
algoritmo.

Este algoritmo también puede trabajar con cualquier clique de partida, siendo posible
utilizarlo como complemento a otras técnicas. Para evaluar su funcionamiento, tomaremos
como clique inicial un clique vacío, que creará un clique maximal de forma aleatoria
y a partir de él explorará su entorno.

Pasamos a ver el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{Búsqueda local 2}
  \begin{algorithmic}
    \State $i = 0$
    \State $Tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If{$C_0 - Tabu$ no es vacío}
        \State Añadir un nodo aleatorio de $C_0 - Tabu$
      \ElsIf{$C_1 - Tabu$ no es vacío}
        \State Hacer un cambio con un nodo aleatorio de $C_1 - Tabu$.
        \State Añadir el nodo a la lista tabú que sale del clique a $Tabu$
        \State $i = i + 1$
      \ElsIf{$C_0$ es no vacío}
        \State Añadir un nodo aleatorio de $C_0$.
      \EndIf
      \State Actualizar $C_0, C_1$
      \State Entorno = $C_0 \cup (C_1 - Tabu)$
    \Until{$i = limite$ o el entorno sea vacío.}
    \State{Devolver mejor clique encontrado}
  \end{algorithmic}
\end{algorithm}

\section{Enfriamiento simulado}

El enfriamiento simulado es un algoritmo de búsqueda en entornos, que incluye un criterio probabilístico
de aceptación de soluciones basado en la termodinámica, el algoritmo de Metrópolis. Fue introducido formalmente en 1983.

Su principal objetivo es evitar que la búsqueda finalice en un óptimo local, permitiendo que algunos
movimientos vayan a soluciones peores. Para ello, usará una función de probabilidad que controle
los movimientos a soluciones peores, probabilidad que disminuirá a medida que avanza el algoritmo.
Así, conseguimos una diversificación de soluciones al principio, mientras que al final del algoritmo
intensificamos la búsqueda en una región concreta del espacio de soluciones.

Esta función de probabilidad estará basada en el valor de una variable, que se suele llamar temperatura,
en referencia a su origen termodinámico. Su forma de actuar es la siguiente: si nos movemos a una solución
que mejore el resultado anterior, la aceptamos directamente. De no ser así, calculamos la diferencia
del valor de la función objetivo, que notamos $\Delta F$, y tomamos como probabilidad de aceptación
$e^{\nicefrac{\Delta F}{T}}$, donde $T$ representa la temperatura. Como $\Delta F \leq 0$, este valor estará
siempre comprendido entre $0$ y $1$.

La temperatura irá disminuyendo en cada iteración, hasta que se alcance una temperatura final. Esto hace
que al principio, el criterio de Metrópolis sea aceptado en un gran porcentaje de ocasiones, que irá disminuyendo
conforme lo haga la temperatura, lo que favorece la exploración en la fase inicial y la intensificación
en la fase final. El cambio de la temperatura puede ser de diversas formas, aunque la más usual es multiplicar
por una constante menor que $1$ en cada iteración.

\subsection{Enfriamiento simulado en MCP}

El principal problema a la hora de elaborar un algoritmo de enfriamiento simulado en MCP es la elección
de una función objetivo que permita una exploración amplia del entorno. Las funciones objetivo usuales,
como el tamaño del clique, no difieren de la búsqueda local en la práctica, pues una vez lleguemos a un
óptimo local, normalmente repetirá movimientos de intercambio de forma indefinida, junto a algún
\textit{drop} o \textit{add} ocasional.

Una función objetivo que permita una mayor exploración nos llevaría a que tal vez el algoritmo no
convergiese correctamente a un óptimo. Si bien esto podría corregirse utilizando después un algoritmo
voráz o alguna de las búsquedas locales anteriores, las diferencias entre esto y tomar una solución
inicial aleatoria no serían muy diferentes.

Es posible encontrar algunos trabajos sobre MCP que involucran el enfriamiento simulado. No obstante,
se suelen basar en una representación y una estructura diferentes a las consideradas en este problema,
siendo imposible trasladarlos a este caso. Es posible adaptar algunas de las ideas, pero no el algoritmo
completo. En el caso de este trabajo, se ha implementado un algoritmo que utiliza las nociones
básicas de enfriamiento simulado para ver sus diferencias con la búsqueda local, y un segundo algoritmo
que recoge algunas ideas de un artículo sobre el problema.

\subsection{Primer algoritmo}

Este algoritmo es una adaptación de una búsqueda local a un enfriamiento simulado, utilizando una función
objetivo basada en el tamaño de los cliques. En concreto, el valor de cada clique es su tamaño más el número
de vértices que contiene el conjunto $C_0$ dividido por el número de vértices totales. De esta forma,
conseguimos que cliques de mayor tamaño tengan siempre un valor mayor que aquellos con menor tamaño, independientemente
del conjunto $C_0$, lo que garantiza la convergencia a un óptimo local. Usando el tamaño de $C_0$ podemos
distinguir entre cliques del mismo tamaño.

Para el entorno, he considerado movimientos \textit{add}, \textit{swap} y \textit{drop}, sin priorizar
ninguno de ellos. Se tomarán en orden aleatorio hasta encontrar uno que mejore o satisfaga el criterio de
Metrópolis.

Los valores de temperatura han sido inicializados a $T_{\text{inicial}} = 1, T_{\text{final}} = 0.01$, con un
mecanismo de enfriamiento geométrico, consistente en multiplicar la temperatura por una constante $\beta$, fijada a
$\beta = 0.99$. Una vez se alcance una temperatura menor que la final, completamos el mejor clique encontrado añadiendo
tantos nodos como sea posible (aunque lo más probable es que no se añada ninguno), eligiendo por mayor número de
adyacencias, y posteriormente el algoritmo finaliza, devolviendo dicho clique.

El algoritmo trabaja siempre partiendo del clique vacío. No obstante, puede ser adaptado fácilmente para que
comience la exploración desde cualquier clique, lo que nos permitiría combinarlo con otros algoritmos.

Vemos una descripción del algoritmo en pseudocódigo.

\begin{algorithm}[H]
\caption{Enfriamiento Simulado}
  \begin{algorithmic}
    \State $T = 1$
    \State $T_{\text{final}} = 0.01$
    \State $\beta = 0.99$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \State Entorno = $C_0 \cup C_1 \cup$ Drops
      \Repeat
        \State Sacar un clique del entorno, calcular $\Delta F$.
        \If{$\Delta F \geq 0$}
          \State Aceptar solución.
          \State Salir del bucle interno.
        \Else
          \State Aceptar solución con probabilidad $e^{\nicefrac{\Delta F}{T}}$.
          \State Salir del bucle interno si se acepta la solución.
        \EndIf
      \Until{Entorno $= \emptyset$.}
      \State $T = T \times \beta$
    \Until{$T < T_{\text{final}}$}
    \State{Ampliar mejor clique encontrado y devolver el resultado.}
  \end{algorithmic}
\end{algorithm}

\subsection{Segundo algoritmo}

En el segundo algoritmo, se han adaptado las ideas de X. Geng, J. Xu, J. Xiao y L. Pan, que propusieron un
algoritmo de enfriamiento simulado para MCP. Dicho algoritmo sigue un enfoque distinto al de este problema,
pues intenta buscar cliques de un tamaño predeterminado, explorando el espacio de soluciones hasta
que lo encuentra, o hasta llegar a un criterio de parada. Se basa en una representación por permutaciones
del vector de vértices, y va realizando intercambios de dos vértices, de tal forma que uno sale del
subgrafo y otro entra en él, siempre que la función objetivo mejore o se satisfaga el criterio de Metrópolis.
En este caso, en lugar de ir moviéndose entre cliques, se consideran grafos de tamaño fijo, que se modificarán
con el objetivo de alcanzar un clique. Esto permite definir como función objetivo el número de aristas que le
faltan al grafo para ser un clique.

Para poder adaptarme a este enfoque, he tenido que diseñar un algoritmo que se moviera entre grafos que no
fueran un clique. He utilizado los mismos tres operadores que he usado anteriormente,
\textit{add, swap} y \textit{drop}, pero en este caso, he permitido añadir cualquier nodo al clique
o intercambiar dos nodos cualesquiera, sin necesidad de respetar la estructura de clique.
La exploración del nuevo entorno se hace igual que en el caso anterior, de forma aleatoria.

Inicialmente, como función objetivo tomé la propuesta en el artículo, consistente en el número de aristas necesarias
para que el grafo pase a ser un clique. Sin embargo, esta función no asegura una convergencia a óptimos locales;
en particular, es ajena al tamaño de los cliques. Por esto, he usado la longitud de los grafos para corregir esta,
restándola al número de aristas restante. Así, tenemos una función objetivo que es menor cuanto mayor es el grafo,
y cuanto más se parece a un clique.

Una vez definida la función objetivo, el algoritmo opera como cabría esperar, explora el entorno y toma un elemento
aleatorio hasta que la función objetivo es menor, o hasta que se acepta el criterio de Metrópolis. Como ahora no
trabajamos con cliques, el grafo que obtenemos será reducido a un clique eliminando el nodo que menos adyacencias
tenga hasta quedarnos con un clique. Este clique no sustituye al grafo que tengamos, sino que se compara con el
mejor obtenido hasta el momento, reemplazándolo si su longitud fuera mayor.

He vuelto a tomar los valores $T_{\text{inicial}} = 1, T_{\text{final}} = 0.01, \beta = 0.99$ para los parámetros
del algoritmo. Una vez finaliza la fase de enfriamiento, vuelvo a añadir tantos nodos como sea posible al mejor
clique encontrado, mediante un algoritmo \textit{greedy}, devolviendo el clique resultante.

Como el algoritmo es similar al anterior, difiriendo en el entorno y en la función objetivo,
no vemos el pseudocódigo, pues sería casi idéntico al anterior.

\section{Búsquedas multiarranque}

Las búsquedas multiarranque son un tipo de búsqueda local, que intentar salir de óptimos locales
empezando de nuevo la búsqueda mediante distintas técnicas. La forma de reiniciar la búsqueda será
la clave para distinguirlas, y estos métodos pueden ser muy diversos. Podemos distinguir los siguientes:

Búsqueda multiarrranque básica, que genera una solución inicial aleatoria y explora su entorno
medianto búsqueda local, proceso que se repite hasta que se satisfaga una condición.

Métodos constructivos de la solución inicial, donde esta varía en cada iteración. Se construye dicha
solución y se explora el entorno hasta llegar a un óptimo local, proceso que se repite asta
satisfacer una condición, que será usualmente un número de iteraciones fijo.

Métodos basados en la modificación del óptimo encontrado, en los que el óptimo local se somete
a una perturbación, dando lugar a una nueva solución de partida. Nuevamente, repetiremos el
proceso hasta alcanzar una condición, que habitualmente será un número de repeticiones dado.

En este trabajo he considerado dos algoritmos de este tipo; uno basado en construcción de la solución
inicial, el algoritmo GRASP (\textit{Greedy Randomized Adaptative Search Procedure}), y otro basado
en modificaciones, el algoritmo ILS (\textit{Iterated Local Search}). Vamos a detallarlos.

\subsection{GRASP}

El algoritmo GRASP, o \textit{greedy} aleatorizado, es un algoritmo multiarranque que consiste en repetir
una fase de construcción de una solución, seguida de una búsqueda local en el entorno de dicha solución,
hasta que se alcance una condición, que suele ser un límite de iteraciones o de tiempo de ejecución.
Suele ser un algoritmo sencillo de programar, y que ofrece buenos resultados en general.

La construcción de la solución inicial sigue un procedimiento \textit{greedy}, en el cual, en lugar de
proporcionar un único candidato, como se haría en un algoritmo \textit{greedy}, se proporcionan
varios de los mejores, y de entre estos, elegiremos uno al azar. El número de candidatos a considerar
puede dejarse como parámetro, o fijarse de antemano, quedando la decisión en manos del programador.
Esta técnica se utiliza para proporcionar diversidad, pues esta se suele perder al tomar soluciones iniciales
generadas por algoritmos voraces.

Una vez construída la solución inicial, se explora su entorno siguiendo una búsqueda local, hasta alcanzar
un óptimo local. Una vez alcanzado, se compara la solución con la mejor obtenida hasta el momento, se
actualiza si es necesario, y se comienza de nuevo el algoritmo. Se repetirá el proceso hasta satisfacer
una condición de parada.

\subsubsection{GRASP en MCP}

El aspecto fundamental de este algoritmo es la construcción de la solución inicial. Podemos valorar
los elementos del conjunto de candidatos de distintas formas, lo que dará lugar a distintas soluciones
de partida. Por lo demás, el algoritmo se basa en una búsqueda local, que hemos discutido con anterioridad.

\subsubsection{Algoritmo implementado}

Como se acaba de mencionar, el aspecto fundamental de este algoritmo es la generación de la solución inicial.
Para ello, he tomado la lista de candidatos, $C_0$, y la he ordenado por número de adyacencias en el grafo,
en orden descendente. Una vez ordenada, tomo la mitad superior, y hago una elección aleatoria entre los nodos.
El proceso se repetirá hasta que $C_0$ sea vacío.

La fase de búsqueda local utiliza los dos métodos ya implementados, lo que da lugar a dos versiones del algoritmo,
en las que solo varía la búsqueda local. Como estos métodos no se detienen en un óptimo, sino que necesitan
un número de iteraciones máximo, he fijado dicho valor al número de vértices del grafo, para que se adapte
al tamaño de cada problema.

Este proceso se repetirá un número determinado de iteraciones, que se pasará como parámetro. Para este caso
se ha fijado a $30$ en todas las instancias disponibles. Almacenaremos la mejor solución obtenida, que será
la que el algoritmo devuelva al final.

Vemos el pseudocódigo del algoritmo y de la generación de soluciones iniciales.

\begin{algorithm}[H]
\caption{GRASP}
  \begin{algorithmic}
  \Repeat
    \State Obtener solución inicial.
    \State Aplicar búsqueda local a la solución inicial.
    \State Actualizar mejor solución.
  \Until{Se alcance el número de iteraciones.}
  \State{Devolver mejor solución obtenida.}
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Generación de soluciones aleatorias}
  \begin{algorithmic}
    \State $Clique = \emptyset$
    \State $C_0 =$ vértices
    \Repeat
      \State Ordenar $C_0$ por adyacencias.
      \State Tomar la mitad superior de $C_0$.
      \State Añadir un elemento aleatorio a $Clique$.
      \State Recalcular $C_0$.
    \Until{$C_0 = \emptyset$}
    \State Devolver $Clique$
  \end{algorithmic}
\end{algorithm}


\subsection{ILS}

La búsqueda local iterada, o ILS (del inglés, \textit{Iterated Local Search}), es un algoritmo de
búsqueda local multiarranque basado en la perturbación de soluciones como método para obtener diversidad.
Fue propuesta en 1998 por Thomas Stützle en su tesis doctoral, y desde entonces se utiliza en la resolución
de distintos problemas, entre los que se encuentra el problema del clique máximo.

El algoritmo ILS requiere de cuatro componentes principales: una solución inicial, un algoritmo de mutación de
soluciones, un método de búsqueda local, y un criterio de aceptación.

El funcionamiento general de este tipo de algoritmos es el siguiente: primero, se toma la solución inicial
y se le aplica búsqueda local, hasta llegar a un óptimo local. Seguidamente, se le aplica una mutación a la
solución obtenida, que nos permite crear una nueva solución inicial a la que volver a aplicar búsqueda local.
Una vez finalizada esta segunda búsqueda local, se usa el criterio de aceptación para ver si reemplazamos
la solución anterior con la obtenida. Este proceso mutación-búsqueda local-aceptación se repetirá hasta
que se satisfaga un criterio de parada. Finalmente, el algoritmo devuelve la mejor solución encontrada.

Este modelo de ILS es el más básico que existe, pero no es el único. Podemos utilizar un modelo basado en
poblaciones, donde a cada elemento se le aplica ILS y estos se combinan de alguna forma para una mayor exploración
del espacio de soluciones, o el modelo $(\nu + \lambda)$, donde, partiendo de $\nu$ soluciones iniciales,
generamos $\lambda$ hijos a partir de ellas mediante mutación, que compiten para pasar a la siguiente fase.

También es posible establecer diferencias en el criterio de aceptación. Si bien el método más usual es tener
una función objetivo, pueden utilizarse otros, como una selección aleatoria, basada en combinaciones,
o basada en probabilidades, en la que podría utilizarse el algoritmo de Metrópolis, por ejemplo.

\subsubsection{ILS en MCP}

Es sencillo construir una búsqueda local iterada para el problema del clique máximo, partiendo de un
algoritmo de búsqueda local existente. Para ello, son necesarios un criterio de aceptación y una
función de mutación.

\subsubsection{Algoritmo implementado}

Se ha implementado un algoritmo que sigue la filosofía de la búsqueda local iterada básica basado en
el propuesto por A. Grosso, M. Locatelli y W. Pullan, que usa el algoritmo de búsqueda local
DLS, si bien se propusieron algunas modificaciones que aquí no se han tenido en cuenta.
En mi caso, además de DLS, he utilizado el otro algoritmo de búsqueda local implementado,
para comparar las diferencias entre ambos al ser utilizados por ILS.
Vemos a continuación la función de mutación y el criterio de aceptación utilizados.

El algoritmo para mutar un clique consiste en tomar un nodo que no se encuentre en él, eliminar del clique
todos los nodos que no estén conectados a él, y finalmente añadir el nodo. Con este método conseguimos
una solución de partida que se encuentra en una zona distinta del espacio de soluciones, a la vez que
usamos información de la iteración anterior para movernos por soluciones que serán potencialemente de calidad.

La función de aceptación se queda siempre con el último clique obtenido tras la búsqueda local. Tras valorar
si quedarme con la última o con la mejor encontrada, decidí hacer lo primero, para favorecer la diversidad en
las soluciones. No obstante, siempre dispondremos de la mejor solución, pues la tendremos guardada, por lo
que modificar el criterio no supone ninguna dificultad.

Dado que las dos búsquedas locales implementadas requieren de un límite como criterio de parada, he fijado dicho
límite al número de vértices del grafo, para que se adapte al tamaño de cada problema. Además, el criterio de
parada del algoritmo también es un número de iteraciones, que ha sido $30$ para todas las instancias.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ILS}
  \begin{algorithmic}
    \State Generar solución inicial.
    \State Aplicar búsqueda local.
    \Repeat
      \State Modificar solución.
      \State Aplicar búsqueda local a la solución obtenida.
      \State Actualizar la mejor solución, si es necesario.
    \Until{Se alcance el número de iteraciones.}
    \State{Devolver mejor solución obtenida.}
  \end{algorithmic}
\end{algorithm}

\section{Algoritmos de colonia de hormigas}

Los algoritmos de colonia de hormigas o ACO (del inglés, \textit{Ant Colony Optimization}) son una técnica
basada en adaptación social, que se basa en el comportamiento de las colonias de hormigas para tratar
de encontrar caminos en grafos. Para ello, utilizará un recurso que emula a las feromonas que emiten las
hormigas cuando se desplazan, y que puede ser detectadas por ellas, lo que permite que las hormigas puedan
recorrer caminos de ida y vuelta al hormiguero siguiendo dicho rastro. Este hecho, unido al pésimo sentido
de la vista que poseen las hormigas, hace que tengan que depender fuertemente del rastro de feromonas para
moverse.

Su fundamentación teórica hace que sea un algoritmo muy eficaz para problemas que requieren de construcción
de caminos, como el problema del viajante de comercio. En general, son algoritmos que funcionan bien
cuando trabajan sobre estructuras similares a los grafos.

La elección por parte de una hormiga del camino que recorrer se fundamenta en un criterio probabilístico.
La hormiga tiende a recorrer caminos en los que el rastro de feromona es mayor, aunque podrá ir por otros
donde el rastro no sea tan intenso. Así, se va acumulando feromona en los caminos más recorridos, mientras
que esta se va evaporando de los caminos menos transitados, reduciendo su concentración.

La acción continuada de la colonia de hormigas da lugar a un rastro de feromona, que permite a las hormigas
encontrar un camino cada vez más corto desde el hormiguero a su destino, usualmente una fuente de alimento.

Este comportamiento será trasladado a la optimización por colonia de hormigas, mediante la construcción
de hormigas artificiales. Cada una de ellas usa un rastro de feromona (artificial), que cambia con el
tiempo, y también usa información heurística de problema para crear un mecanismo probabilistico de
construcción de soluciones.

Esta hormiga será la encargada de ir recorriendo el grafo, utilizando la información de la que dispone para
decidir a qué nodo moverse mediante una función de probabilidad. Los nodos que compongan una solución
serán reforzados con un aumento de feromonas, y se hará de forma que mejores soluciones reciban más cantidad
de feromona. Se utiliza también un mecanismo de evaporación de feromona para evitar un incremento ilimitado,
simulando el proceso que ocurre en la realidad. Para esto, se reducirán todos los rastros de feromona eliminando
un porcentaje de su valor actual. En la práctica, esto se traduce en evitar un estancamiento del algoritmo en
óptimos locales.

Por norma general, se lanzarán un número determinado de hormigas artificiales independientes, las cuales generan
una solución cada una. Entre ellas, elegiremos la mejor, y esta será la que cambie los niveles de feromona.
Este proceso se repite hasta que se satisfaga una condición de parada, que suele ser un número de iteraciones o un
límite temporal

Existen numerosas variantes de las colonias de hormigas, dependiendo de la función de probabilidad, la
actualización de feromonas, etcétera. También es posible hibridar este método con otros, usualmente una
búsqueda local, aplicando el método a cada hormiga de la colonia una vez ha construído su solución.

\subsection{ACO en MCP}

Al ser el problema del clique máximo un problema de grafos, los algoritmos de colonias de hormigas son
fácilmente implementables, y se pueden esperar buenos resultados en su ejecución. Si bien en MCP
no tratamos de recorrer un grafo, como se haría en el problema del viajante de comercio, el concepto
es adaptable para trabajar con conjuntos de candidatos para realizar alguna acción, como un \textit{add}
o un \textit{swap}.

En este trabajo, he considerado dos algoritmos de colonias de hormigas clásicos, lanzando una colonia de hormigas
durante un número determinado de iteraciones y reforzando el nivel de feromonas en las soluciones de calidad.
La evaporación se realiza reduciendo un porcentaje de feromona, fijo en todas las iteraciones. La diferencia entre
ambos algoritmos reside en la función de probabilidad; mientras que uno de ellos utiliza solo las feromonas,
el segundo complementa el uso de las feromonas con información del grafo.

\subsection{Primer algoritmo}

El primer algoritmo implementa una colonia de hormigas básica, en la que un número fijo de hormigas crean
una solución cada una, y la mejor es la que se tiene en cuenta para modificar los niveles de feromonas.
He considerado únicamente movimientos \textit{add}, por lo que las hormigas irán recorriendo los nodos
del conjunto $C_0$ hasta que este sea vacío.

Cada hormiga comenzará desde un clique vacío y añadirá nodos del conjunto $C_0$ según una regla probabilística,
que consiste en dar a cada nodo del conjunto una probabilidad en base a su feromona, normalizándola para obtener
un valor entre $0$ y $1$, y siendo $1$ la suma de todas las probabilidades de los nodos do $C_0$. Inicialmente,
la probabilidad será la misma para cada nodo.

El proceso se repite hasta que la hormiga finaliza la creación de su clique, dando paso a la siguiente, que crea
uno distinto, y así hasta que todas las hormigas completen el suyo. Cada vez que una hormiga finaliza, compara
su clique con el mejor obtenido en esa iteración, sustituyéndolo de ser necesario.

Una vez finalizado el trabajo de todas las hormigas, se produce la evaporación de feromona, consistente en
multiplicar los valores en cada nodo por una constante $\beta$. Seguidamente, se aumentan los niveles de feromona
en los nodos de la mejor solución, multiplicando el valor de esta por un valor $\alpha$. Este valor depende
del tamaño del clique encontrado, siendo mayor cuanto más tamaño tiene el clique. Así, conseguimos dar más
peso a soluciones de más calidad.

El proceso se repite un número fijado de iteraciones. Una vez terminadas todas las iteraciones, el algoritmo
finaliza y devuelve la mejor solución encontrada.

Se han fijado los valores $\beta = 0.925$, $\alpha = (5 \times |C| + N) / N$, donde $|C|$ es el tamaño del clique
encontrado, y $N$ es el número de vértices del grafo. Para fijarlos, me he valido de la experimentación,
tomando aquellos que daban mejores resultados en un conjunto reducido de instancias. No obstante, las diferencias
eran mínimas.

El número de hormigas en cada iteración ha sido fijado a $50$, efectuándose un total de 40 iteraciones.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ACO 1}
  \begin{algorithmic}
    \State $T_{\text{final}} = 0.01$
    \State Inicializar constantes $\alpha, \beta$.
    \State $Mejor Clique = []$.
    \Repeat
    \State $Hormigas = 0$.
      \State Establecer el mejor clique de la colonia al clique vacío.
      \Repeat
        \State $Clique = []$
        \State Añadir vértice aleatorio al clique
        \State Calcular $C_0$
        \Repeat
          \State Calcular probabilidades de los nodos en $C_0$. Normalizar.
          \State Elegir un nodo según la probabilidad y añadirlo a clique.
          \State Recalcular $C_0$.
        \Until{$C_0 = \emptyset$}
        \State Actualizar el mejor clique de la colonia si es necesario.
        \State $Hormigas = Hormigas + 1$.
      \Until{$Hormigas = $ límite hormigas}
      \State Actualizar $Mejor Clique$ si es necesario.
      \State Evaporar feromona.
      \State Aportar feromona a los nodos del mejor clique de la colonia.
      \State $i = i+1$.
    \Until{$i = limite$}
    \State{Devolver mejor clique encontrado.}
  \end{algorithmic}
\end{algorithm}


\subsection{Segundo algoritmo}

Este algoritmo toma algunas de las ideas de X. Xu, J. Ma y J. Lei, que trata de mejorar el ACO básico considerando
información relativa al clique para calcular las probabilidades de elegir un nodo. La única diferencia con el anterior
está dicho cálculo, para el que utilizaremos una técnica de enfriamiento simulado.

La probabilidad se compone de dos partes: la primera de ellas es idéntica a la anterior, un valor entre $0$ y $1$
obtenido de las feromonas de cada nodo en $C_0$, noralizando para que la suma total sea $1$. Además, sumaremos un
valor que depende del grado de cada nodo, y estará multiplicado por una temperatura, de forma que la importancia
de este término desciende en el tiempo. La fórmula para el cálculo de la probabilidad queda como
\[ p(v_i) = \frac{\tau(v_i)}{\sum_{v_j \in C_0} \tau(v_j)} + T \frac{D(v_i)}{N} \]
donde $\tau(v_i)$ es el valor de la feromona en el nodo $v_i$, $T$ es la temperatura, $N$ el número de nodos
del grafo, y $D(v_i)$ es el grado de $v_i$. Una vez calculadas todas las probabilidades de los nodos de $C_0$,
las normalizaremos para tener valores entre $0$ y $1$ y que la suma siga siendo $1$.

La temperatura sigue un esquema de descenso geométrico similar al utilizado en los algoritmos de enfriamiento simulado,
en los que la temperatura se multiplica por una constante $\gamma$ en cada iteración. Dicho valor se ha fijado a
$\gamma = 0.95$. Los valores de $\alpha$ y $\beta$ siguen siendo los mismos que en el algoritmo anterior, al igual
que el número de hormigas y de iteraciones, que son $50$ y $40$ respectivamente.

Puesto que solo cambia la función del cálculo de la probabilidad, no incluyo pseudocódigo de este algoritmo,
por ser idéntico al anterior.

\section{Algoritmos genéticos}

Los algoritmos genéticos entran dentro de la llamada \textbf{computación evolutiva},
que está compuesta por modelos de evolución basados en poblaciones. Se basan en
los procesos evolutivos que están presentes en la naturaleza, en los que dos padres
combinan sus genes para producir hijos (usualmente dos), los cuales presentan
características de ambos, y las diferencias entre generaciones pueden llevar a nuevas
características que conlleven una mejor adaptación al entorno. Esto, en el ámbito
que nos encontramos, se traduce en cambios que nos lleven a una mayor adaptación
al problema, lo que nos da mejores soluciones.

En los algoritmos genéticos, las poblaciones estarán formadas por soluciones al
problema, que combinaremos dos a dos para producir descendientes que intenten mejorar
a sus progenitores. Esta combinación de soluciones se produce mediante el llamado
\textbf{operador de cruce}, que emula cómo los cromosomas se mezclan para producir
una nueva generación. Este operador dependerá del problema y no tiene por qué ser único.
El requisito fundamental es que se tome información de ambos progenitores para crear
a sus descendientes.

En la naturaleza, es posible que al combinar dos individuos se produzca una mutación,
con lo cual el hijo tendría una característica que no ha adquirido de ninguno de sus
padres, y que podría conllevar una ventaja o un perjuicio para el mismo. Esta tecnica
se reproducirá en los algoritmos genético, incluyendo la posibilidad de que una
solución mute al ser generada.

Controlaremos el cruce entre individuos y las mutaciones de sus descendientes con
parámetros que establezcan la probabilidad de que ambos sucesos ocurran. Para el
cruce, seleccionaremos dos individuos o bien generarán descendientes, o bien
pasarán directamente a la siguiente generación. En caso de generar descendientes,
cada uno de ellos podrá ser mutado en el momento de su creación.

Existen distintas formas de seleccionar a los padres. El muestreo puede ser aleatorio,
se puede dar mayor probabilidad de combinarse a los mejores, etc. No hay restricción
en cuanto al número de veces que se puede reproducir un elemento, si bien podría
estrablecerse de considerarse necesario.

De igual forma, existen diversos métodos para crear una nueva generación. Una de
ellas sería que los hijos sustituyan a los padres, el llamado modelo generacional.
En este caso, se crea una nueva población en cada iteración del ciclo.
Es posible incluir elitismo, de forma que la mejor solución de la población pasa
siempre a la siguiente generación. Otro modelo es el llamado estacionario, en el
cual se eligen dos padres, que generan dos hijos, y estos compiten para pasar a
la siguiente generación, pudiendo hacerlo con los padres o con la población en
general. Este modelo ya es elitista, luego no necesita introducir elitismo explícitamente.

\subsection{Genéticos en MCP}

Implementar un algoritmo genético para el problema del clique máximo se basa en
considerar operadores de cruce y mutación apropiados, esto es, que mantengan la
estructura de clique. A priori, no podemos afirmar que la combinación arbitraria
de dos soluciones o la mutación produzcan cliques, por lo que estos operadores
deben ser muy específicos o rectificados de alguna forma.

Una vez tengamos estos operadores, la ejecución del algoritmo consiste simplemente
en ir obteniendo nuevas generaciones hasta un criterio de parada determinado.

\subsection{Algoritmo implementado}

El algoritmo genético implementado se basa en un modelo estacionario, en el que
los dos descendientes compiten con sus padres para entrar en la nueva generación.
Al principio, se creará una población de soluciones de forma aleatoria mediante
un algoritmo \textit{greedy}, y a partir de aquí se irán generando nuevas soluciones.

El operador de cruce opera de la siguiente forma: dados dos padres, se toman aquellos
nodos comunes en ambos, y estos estarán presentes en ambos hijos. Seguidamente,
tomaremos el conjunto de nodos presentes en uno de los dos padres, y los distribuiremos
entre los dos hijos de forma aleatoria y equiprobable.

Una vez tengamos los hijos, procedemos a mutarlos con la probabilidad dada. El
algoritmo de mutación toma dos valores aleatorios entre $0$ y el número de nodos,
y cambia los nodos del intervalo que forman, quitándolos del grafo si pertenecen
a él, y metiéndolos en el grafo si no lo hacen.

Como no tenemos garantizado que los hijos sean cliques antes o después de la mutación,
los reduciremos a un clique eliminando nodos hasta que el conjunto restante sea un
clique. Una vez reducido, lo ampliaremos hasta que el clique sea maximal.
Ambos procesos de reducción y ampliación se hacen mediante técnicas \textit{greedy},
quitando el nodo que minimice adyacencias en la reducción, y añadiendo el que las
maximice en ampliación.

La población inicial se ha tomado con un tamaño de $40$ individuos, con probabilidad
de cruce de $1$ y probabilidad de mutación de $0.1$, un valor alto para lo usual,
fijado así para introducir diversidad en la población. El criterio de parada es un
límite de iteraciones, que se ha fijado a $40$ en las ejecuciones realizadas.
Estos parámetros pueden ser modificados para evaluar la funcionalidad del algoritmo
bajo otras circunstancias.

\section{Algoritmos meméticos}

Los algoritmos meméticos son el resultado de la combinación de algoritmos meméticos
con búsqueda local. Tratan de aprovechar la buena capacidad de exploración de los
algoritmos genéticos, y combinarla con la explotación de soluciones de las técnicas
de búsqueda local.

El diseño de estos algoritmos queda muy abierto, y por lo general, suele ser necesario
adaptarlos de una forma u otra dependiendo del problema. Suelen ser algoritmos específicos,
que explotan alguna característica en concreto del problema.

Entre las diversas decisiones que hay que tomar, una de las más relevantes es el
proceso de búsqueda local a considerar y cuándo aplicarlo. Podemos elegir cualquier
técnica por trayectorias simples, desde una búsqueda local básica a una busqueda
tabú, y podemos aplicarlas a toda la población o a una parte, en distintas
fases del algoritmo.

\subsection{Meméticos en MCP}

Debido a que disponemos de técnicas de búsqueda local y algoritmos genéticos,
la implementación de un algoritmo memético consiste en tomar las decisiones
correspondientes con respecto a la hibridación de ambias técnicas.

\subsection{Algoritmo implementado}

En este trabajo, he optado por una combinación básica de dos algoritmos ya implementados,
el algoritmo genético y la búsqueda local. De esta forma, se mantiene la estructura
de algoritmo genético estacionario, introduciendo una búsqueda local al final de
la creación de la nueva generación, lo que nos permite explorar su entorno antes de
pasar a la siguiente. 
