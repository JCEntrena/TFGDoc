%************************************************
\chapter{Algoritmos}\label{ch:algoritmos}
%************************************************

En este capítulo se tratarán los diferentes algoritmos considerados en el trabajo, desde su
fundamento teórico hasta su implementación concreta.

\section{Consideraciones iniciales}

Antes de describir cada algoritmo, vamos a ver consideraciones más generales sobre el problema, que serán
utilizadas en los algoritmos que se implementen. Discutiremos la representación de las soluciones, el
operador de vecindad, la función objetivo y la inicialización del programa.
% Representación de la solución. Inicialización del programa (lectura). Operador vecino. Entorno. Función objetivo.

Cada solución del problema será un clique que se encuentre dentro del grafo. Este clique estará representado
por los nodos que contiene, de forma que las soluciones serán \textit{arrays} de la forma $[x_0, \dots, x_p]$.

La función para medir la calidad de una solución (función objetivo) será el tamaño de cada clique, si bien
se considerarán algunas variantes en ciertos algoritmos. No obstante, como el objetivo final el obtener un clique
del mayor tamaño posible, es lógico que el factor de peso en cualquier función objetivo sea el tamaño del mismo.

Como operador de vecino tenemos tres distintos, los cuales aplicados sobre el clique nos permitirán obtener
su entorno. El primero de ellos, al que llamaremos operador \textit{add}, consiste en añadir al clique un
nuevo nodo que conserve la estructura de clique, esto es, que esté conectado con todos los nodos del clique.
Usualmente tendremos calculado el conjunto de nodos que podemos añadir a cada clique con el que estemos trabajando.
Llamaremos a dicho conjunto $C_0$ o posibles adiciones.

El segundo operador, al que nos referiremos como \textit{swap}, consiste en intercambiar un nodo del clique
con uno de fuera, de forma que se siga manteniendo la estructura. Para ello, el nodo que no pertenece al
clique debe estar conectado con todos salvo uno de sus nodos, que será el nodo que saldrá del clique. Nos
referiremos a este conjunto de nodos como posibles intercambios o $C_1$. Al igual que el anterior, también
tendremos calculado dicho conjunto de nodos para cada clique con el que trabajemos.

Finalmente, el tercer operador de vecino será el operador \textit{drop}, que consiste simplemente en quitar
un nodo del clique. Es claro que se mantiene la estructura de clique al aplicar este operador.

Estos serán los tres operadores que utilicemos, que definirán el entorno de una solución, compuesto por
aquellas a las que se puede llegar mediante el uso de cualquiera de los tres. No obstante, no siempre se
usarán los tres a la vez. El operador \textit{add} es esencial, pues nos permite ampliar el tamaño de un
clique, por lo que siempre lo utilizaremos. Los otros dos operadores se usarán dependiendo del algoritmo,
siendo el operador \textit{swap} bastante frecuente, y el \textit{drop} menos frecuente. Debido a esto,
el entorno variará dependiendo de aquellos consideramos. Detallaremos en cada caso los operadores
considerados y las razones principales.

\subsection{Inicialización del programa}
Antes de aplicar ningún algoritmo al conjunto de instancias, hay que resolver es la lectura de los
archivos y la creación de las estructuras de datos correspondientes para cada grafo. Para ello,
se ha creado el archivo \textit{reader.rb}, que contiene el método de lectura de los archivos.
Cada uno de ellos dará lugar a un objeto de la clase \textbf{Problem}, que almacena el número de
vértices, el número de arcos, la matriz de adyacencia y el nombre del archivo del que proviene el grafo.

Para la lectura, simplemente recorreremos el directorio en el que están almacenados los archivos,
y generaremos un problema por cada uno de ellos, marcando en la matriz de adyacencia los arcos
que están conectados. Almacenaremos el conjunto de problemas en una variable, para tenerlos
disponibles a la hora de aplicarles los algoritmos.

El archivo \textit{reader.rb} también contendrá el método principal, desde donde se ejecutarán
cada uno de los algoritmos. El cambio de algoritmo y el paso de parámetros se harán modificando
el código correspondiente en el método \textit{main}.

Pasamos ya a ver los algoritmos que se han incluido en este trabajo.

\section{Algoritmos \textit{greedy}}

Los algoritmos voraces, o algoritmos \textit{greedy}, son aquellos que resuelven problemas tomando
las decisiones óptimas en cada instante. Esto no lleva necesariamente a un óptimo global, pero puede
aproximarlo de forma razonable en un periodo de tiempo generalmente muy pequeño. Este tipo de algoritmos
basan sus decisiones en las decisiones que ya se han tomado, pero nunca en lo que podría suceder más
adelante.

Por lo general, en los algoritmos \textit{greedy} tendremos un conjunto de candidatos, una función
de selección, que se encarga de elegir al mejor candidato en cada momento, una función objetivo, que
da un valor a cada solución, una función de factibilidad, que elige los candidatos que se pueden incluir
en una solución, y una función que nos dice si tenemos una solución.

Este tipo de algoritmos suelen ser irreversibles, esto es, no se pueden deshacer elecciones ya hechas.
No obstante, existen varios tipos de algoritmos \textit{greedy}, en los que esta condición se relaja. Así,
distinguiremos entre algoritmos \textit{greedy} puros, relajados y ortogonales. En este trabajo se han
implementado dos algoritmos \textit{greedy}, uno puro y otro relajado.

\subsection{\textit{Greedy} en MCP}

En el problema del clique máximo, los algoritmos \textit{greedy} tienen dos enfoque principales:
o bien se parte de un conjunto vacío y se añaden vértices, respetando la estructura de clique,
hasta que no sea posible añadir más, o partimos del conjunto total de vértices y vamos eliminando
nodos hasta que el grafo obtenido sea un clique.

Los dos algoritmos \textit{greedy} que he implementado siguen el primer enfoque de los
mencionados anteriormente. Se diferencian principalmente en la elección del vértice que
se añade al clique, aunque en uno de ellos modificaremos también la estructura de entornos,
considerando intercambios además de adiciones.

A continuación, se detallan en más profundidad los dos algoritmos implementados:

\subsection{Primer algoritmo}

Este algoritmo es el enfoque más básico posible dentro de los algoritmos voraces para MCP.
Comenzando desde un clique vacío, añade nodos al clique, respetando la estructura, hasta
que no se pueda añadir ninguno más. Para elegir el vértice que añadir, toma, de aquellos que
pueden añadirse, el que tiene mayor número de adyacencias, usando el operador \textit{add}.
Otras posibles opciones serían elegir un nodo aleatorio entre los disponibles o tomar aquel que
maximice el tamaño del conjunto $C_0$ al añadirse al clique.

Este algoritmo es irrevesible, pues los nodos que se añadan al clique no saldrán de él
en ningún caso.

Vemos a continuación el pseudocódigo del algoritmo.

\begin{algorithm}[H]
\caption{Greedy}
  \begin{algorithmic}
  \State $Clique = [ ]$
  \State $C_0 = $ Vértices
  \Repeat
    \State{Añadir $v \in C_0$ con más adyacencias}
    \State{Actualizar $C_0$}
  \Until{$C_0 = \emptyset$}
  \State{Devolver clique}
  \end{algorithmic}
\end{algorithm}


\subsection{Segundo algoritmo}

En este algoritmo, se han seguido las ideas de Grosso, Locatelli y Della Croce, usando un algoritmo
que nos permite deshacer, en cierta forma, decisiones tomadas anteriormente. La idea es no solo
considerar aquellos vértices que pueden ser añadidos al clique, sino también tomar aquellos que
pueden ser intercambiados por uno del clique, es decir, usar operadores \textit{add} y \textit{swap}.

El criterio para elegir un nodo será el número de conexiones con el conjunto de posibles adiciones
al clique, buscando maximizar este número. Así, al añadir el nodo al grafo, el tamaño del conjunto
$C_0$ será el máximo de los posibles. Como dicho tamaño es una cota para el número de nodos que se
pueden añadir al clique, nos interesa que sea lo más elevado posible.

Antes de empezar a considerar intercambios, queremos que el clique tenga un tamaño mínimo.
Se ha fijado dicho tamaño en $4$, valor a partir del cual se empiezan a considerar los
intercambios y no solo las adiciones. Detendremos el algoritmo una vez lleguemos a un
clique maximal, esto es, cuando el conjunto $C_0$ sea vacío. No obstante, se ha fijado
un valor máximo de intercambios para evitar que el algoritmo se prolongue durante mucho tiempo.
Una vez satisfecha alguna de estas condiciones, el clique que tengamos será ampliado
hasta su límite usando movimientos \textit{add}, finalizando cuando no sea posible
añadir más nodos. Esta ampliación se realiza por si el algoritmo se ha detenido al
alcanzar el límite de intercambios, lo que significa que es posible añadir más nodos.

Para evitar repetición de intercambios, en el momento en el que se haga uno, guardaremos
el nodo que sale del clique, para no tenerlo en cuenta en la siguiente iteración.
De no hacer esto, cabe la posibilidad de entrar en un bucle, en el que se
intercambien dos nodos de forma indefinida hasta que se alcance el criterio de parada.

Vemos a continuación el pseudocódigo de la parte adaptativa del algoritmo.


\begin{algorithm}[H]
\caption{Greedy adaptativo}
  \begin{algorithmic}
  \State $Clique = [ ]$
  \State $C_0 = $ Vértices
  \State $C_1 = [ ]$
  \State $i = 0$
  \Repeat
    \State Tomar $v \in C_0 \cup C_1 - Swap$ que maximice adyacencias con $C_0$
    \If {$v \in C_0$}
      \State Añadir $v$ a $Clique$
    \Else
      \State Hacer intercambio
      \State Actualizar $Swap$, $i += 1$
    \EndIf
    \State{Actualizar $C_0, C_1$}
  \Until{$C_0 = \emptyset$ o $i = limite$}
  \State{Devolver clique}
  \end{algorithmic}
\end{algorithm}


\section{Búsqueda local}

Los algoritmos de búsqueda local son aquellos que se centran en el entorno de una
solución para buscar nuevas soluciones que sean mejores que la anterior. Dicho entorno
viene dado por aquellas soluciones a las que se puede llegar desde la solución de
partida mediante un \textbf{operador de vecindad}. Llamaremos a estas soluciones
\textbf{soluciones vecinas}.

Las distintas formas de recorrer el entorno y de aceptar soluciones vecinas da
lugar a los distintos algoritmos de búsqueda local. El criterio de aceptación debe
ser monótona, pues queremos que conduzca a soluciones cada vez mejores, finalizando
en un óptimo local. La búsqueda local básica busca mejorar el resultado con un elemento
del entorno, terminando si este no existe y alcanzando un máximo local. Si queremos
permitir que las soluciones puedan ser peores, existen algoritmos como el enfriamiento
simulado o la búsqueda tabú. En cuando a la estructura de entornos, también puede ser
variable, lo que nos llevaría a una búsqueda en entornos variables o, nuevamente,
a una búsqueda tabú. Todo esto se hace con el objetivo de que nuestro algoritmo
sea capaz de escapar de óptimos locales, y alcance el óptimo global.

Las técnicas de búsqueda local se utilizan no solo como heurísticas para resolver
problemas, sino como complementos de otras. Por ejemplo, pueden ser utilizadas junto
a los algoritmos genéticos para mejorar el conjunto de soluciones, o aplicarse después
de técnicas \textit{greedy} para explorar el espacio de soluciones de la solución
generada. También se usan en técnicas multiarranque como ILS o GRASP, que explicaremos
más adelante.

En este trabajo, se han implementado dos técnicas de búsqueda local, que difieren en la
estructura de entornos y en el método de elección de candidatos. Asimismo, se ha implementado
un algoritmo de enfriamiento simulado, y se han incorporado varias de las técnicas mencionadas
anteriormente en otros algoritmos. Estas serán detalladas en cada caso.

\subsection{Búsqueda local en MCP}

En la búsqueda local, las diferencias que hacen a los algoritmos distintos están en la estructura
de entornos y en elección de una solución vecina a la que desplazarse. Estas diferencias son
también las que existen entre los dos algoritmos implementados en este trabajo. Nos valdremos
de los operadores \textit{add, swap} y \textit{drop} como operadores de vecindad, si bien no
siempre los tendremos todos en cuenta.

En el primer algoritmo se consideran los tres movimientos para calcular el entorno.
Si bien esto rompe con la filosofía de que la búsqueda local debe ir a mejores soluciones,
la posibilidad de eliminar elementos del clique se incluye para evitar que estos algoritmos
sean similares a los \textit{greedy}, buscando favorecer una búsqueda en el entorno.

En el segundo algoritmo, solo se consideran movimientos \textit{add} y \textit{swap}.
Si bien puede en principio puede parecer similar al algoritmo \textit{greedy} adaptativo
detallado anteriormente, veremos que tiene varias diferencias fundamentales con respecto
a este.

Veámoslos en más detalle.

\subsection{Primer algoritmo}

Este algoritmo se basa en las ideas de Katayama, Hamamoto y Narihisa. En él, se han considerado
los tres movimientos básicos de la búsqueda local, \textit{add, swap} y \textit{drop}, dando
distintas prioridades a cada uno de ellos. Como nuestro objetivo es construir un clique del
mayor tamaño posible, añadiremos vértices siempre que podamos, tomando aquel que tenga más
conexiones con el conjunto $C_0$ en caso de haber varios. Cuando no sea posible, intentaremos
hacer un swap, siempre que este nos lleve a un escenario en el que podamos añadir más nodos
al clique resultante. La elección de los nodos a intercambiar se hace mediante la técnica del
primer mejor, esto es, tomamos el primero que encontremos. De no poder hacer ningún swap bajo
estas condiciones, eliminaremos del clique el nodo que tenga menos adyacencias con todos los
nodos del grafo.

Para evitar que los nodos que eliminemos sean añadidos inmediatamente al clique, los iremos
acumulando en una lista tabú. Los nodos de esta lista no se tendrán en cuenta a la hora de
hacer un movimiento add. Así, nos aseguramos que el clique cambia, y que no entramos en
un bucle en el que eliminamos un nodo y acto seguido lo volvemos a añadir al clique.
Esta lista tabú será vaciada en el momento en el que se realice un movimiento que no sea
quitar un nodo del clique, pues nos habremos asegurado de que el clique cambia.

Este algoritmo no tiene un criterio de parada inducido por el entorno, pues siempre podremos
hacer alguno de los tres movimientos. Por tanto, es necesario establecer un límite, que este
caso, ha sido establecer un límite de swaps y drops a realizar a lo largo del algoritmo.
Una vez alcanzado este límite, el algoritmo finaliza, devolviendo el mejor clique encontrado.
Para evitar que el límite sea una constante común para todas las instancias, se ha establecido
en proporción al número de vértices del grafo, haciendo que el algoritmo se adapte al tamaño
de cada problema.

El hecho de considerar un criterio de elección sobre los nodos del conjunto $C_0$ y $C_1$ hace que
el orden del algoritmo sea $\mathcal{O}(nl)$, donde $n$ el el tamaño del grafo y $l$ el límite impuesto.

Este algoritmo puede trabajar partiendo desde cualquier clique, lo que nos permite utilizarlo en
técnicas híbridas como algoritmos meméticos, o combinarlo con el uso de un algoritmo \textit{greedy}
para tener una solución de partida prometedora. Para evaluar sus prestaciones por separado,
partirá desde un clique vacío, que es equivalente a pasarle una solución inicial construída
con un algoritmo \textit{greedy} que añada nodos utilizando el mismo criterio que esta búsqueda local.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{Búsqueda local 1}
  \begin{algorithmic}
    \State $i = 0$
    \State $Tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If {$C_0$ no es vacío}
        \State Añadir el nodo de $C_0$ que tenga más conexiones con $C_0$.
        \State $Tabu = \emptyset$
      \Else
        \State Buscar en $C_1$ el primer intercambio que nos da un $C_0$ no vacío.
        \If {El intercambio existe}
          \State Hacer intercambio
          \State $Tabu = \emptyset$
          \State $i = i + 1$
        \Else
          \State Quitar el nodo del clique con más adyacencias en el grafo.
          \State Añadirlo a $Tabu$.
          \State $i = i + 1$
        \EndIf
      \EndIf
      \State{Actualizar $C_0, C_1$, teniendo en cuenta $Tabu$.}
    \Until{$i = limite$}
    \State{Devolver mejor clique encontrado}
  \end{algorithmic}
\end{algorithm}

\subsection{Segundo algoritmo}

Este algoritmo está basado en la búsqueda local dinámica o DLS (del inglés, \textit{Dynamic Local Search}),
propuesta por W. Pullan y H. Hoos en el año 2006, y en concreto, se basa en una adaptación hecha
por A. Grosso, M. Locatelli y W. Pullan para un algoritmo de búsqueda local iterada, que veremos
más adelante. Sigue una filosofía más simple que el anterior pues solo considera movimientos
\textit{add} y \textit{swap}, a los que volveremos a ordenar por prioridad. Además, incluye una
lista tabú con los nodos que han salido del clique mediante un swap, evitando que vuelvan a entrar
al clique y proporcionando diversidad. Limitaremos la longitud de esta lista a un 2\% del número
de vértices en el grafo, para que no aloje un gran número de nodos.

Nuestro entorno consistirá en el conjunto de posibles adiciones ($C_0$) y el conjunto de
posibles intercambios ($C_1$), al que quitaremos la lista tabú. Como teóricamente, el entorno
puede ser vacío, si se diera el caso el algoritmo finalizaría. No obstante, se ha establecido un
límite de intercambios, pues en la práctica el entorno no tiene por qué ser vacío.

La prioridad entre movimientos es la siguiente: primero intentaremos añadir un elemento de
$C_0$ que no esté en la lista tabú, comprobando si existe alguno, y tomando uno aleatorio
en caso de existir varios. De no existir ninguno, tomaremos el conjunto $C_1$ y le quitaremos
la lista tabú. En caso de quedar algún nodo, haremos el intercambio, que volverá a ser aleatorio
si tenemos varios candidatos. Dicho nodo será añadido a la lista tabú para evitar que vuelva
a entrar al clique en las iteraciones más inmediatas. Finalmente, en caso de que este conjunto
también fuera vacío, solo nos queda la posibilidad de añadir un elemento de la lista tabú que
esté en $C_0$. Nuevamente, elegiremos uno aleatorio entre los existentes.

Este proceso se repetirá hasta que se satisfaga uno de los dos criterios de parada. Una vez
acabe el algoritmo, devolveremos el mejor clique que haya encontrado.

Como en este caso la elección de nodos es aleatoria, se considera un único bucle,
luego la complejidad de este algoritmo es lineal sobre el límite establecido,
$\mathcal{O}(l)$. Debido a esto, ofrecerá mejores tiempos de cómputo que el otro
algoritmo de búsqueda local implementado.

Este algoritmo también puede trabajar con cualquier clique de partida, siendo posible
utilizarlo como complemento a otras técnicas. Para evaluar su funcionamiento, tomaremos
como clique inicial un clique vacío, y dado el orden de prioridad de los movimientos,
el algoritmo creará un clique maximal de forma aleatoria y a partir de él explorará
su entorno.

Pasamos a ver el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{Búsqueda local 2 - DLS}
  \begin{algorithmic}
    \State $i = 0$
    \State $Tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If{$C_0 - Tabu$ no es vacío}
        \State Añadir un nodo aleatorio de $C_0 - Tabu$
      \ElsIf{$C_1 - Tabu$ no es vacío}
        \State Hacer un cambio con un nodo aleatorio de $C_1 - Tabu$.
        \State Añadir el nodo a la lista tabú que sale del clique a $Tabu$
        \State $i = i + 1$
      \ElsIf{$C_0$ es no vacío}
        \State Añadir un nodo aleatorio de $C_0$.
      \EndIf
      \State Actualizar $C_0, C_1$
      \State Entorno = $C_0 \cup (C_1 - Tabu)$
    \Until{$i = limite$ o el entorno sea vacío.}
    \State{Devolver mejor clique encontrado}
  \end{algorithmic}
\end{algorithm}

\section{Enfriamiento simulado}

El enfriamiento simulado es un algoritmo de búsqueda en entornos, que incluye un
criterio probabilístico de aceptación de soluciones basado en la termodinámica,
el algoritmo de Metrópolis. Fue introducido formalmente en 1983.

Su principal objetivo es evitar que la búsqueda en el entorno finalice en un óptimo
local, cosa que ocurre con la búsqueda local. Para esto, permitirá que algunos
movimientos vayan a soluciones peores, usando una función de probabilidad que decida
si se acepta un movimiento a una solución de menos calidad. Esta probabilidad vendrá
dada por el algoritmo de Metrópolis, e irá descendiendo a medida que avanza el algoritmo.
Así, conseguimos una diversificación de soluciones al principio, mientras que al final
del algoritmo intensificamos la búsqueda en una región concreta del espacio de soluciones.

El algoritmo de Metrópolis utiliza dos valores para calcular la probabilidad. Uno de ellos
es la diferencia entre los valores de la función objetivo de la solución del entorno y
la solución actual. El otro es un valor llamado temperatura, en referencia a su origen
termodinámico, que desciende en cada iteración de la búsqueda, lo que permitirá que
la probabilidad descienda con el valor.

Su forma de actuar es la siguiente: si nos movemos a una solución que mejore el resultado
anterior, la aceptamos directamente. De no ser así, calculamos la diferencia del valor de
la función objetivo, que notamos $\Delta F$, y tomamos como probabilidad de aceptación
$e^{\nicefrac{\Delta F}{T}}$, donde $T$ representa la temperatura. Como $\Delta F \leq 0$,
este valor estará siempre comprendido entre $0$ y $1$, siendo más cercano a $0$ cuanto
menor sean la temperatura y $\Delta F$.

El decrecimiento de la temperatura nos proporciona también un criterio de parada. Fijando
una temperatura final, usualmente cercana a $0$, el algoritmo se ejecutará hasta que la
temperatura alcance dicho valor. Así, conseguimos que la probabilidad de aceptación de
soluciones peores sea mayor al principio, favoreciendo la exploración, mientras que en
las fases finales la probabilidad de aceptación será baja, y el algoritmo intensificará
la búsqueda en la región del espacio de soluciones que se encuentre.

El descenso de la temperatura puede seguir distintos esquemas, aunque el más usual es el
geométrico, consistente en multiplicar la temperatura por una constante menor que $1$
en cada iteración. No obstante, cualquier función estrictamente decreciente nos resultaría
útil para realizar dicho descenso.

\subsection{Enfriamiento simulado en MCP}

El principal problema a la hora de elaborar un algoritmo de enfriamiento simulado en MCP
es la elección de una función objetivo que permita una exploración amplia del entorno.
Las funciones objetivo usuales, como el tamaño del clique, no aportan diversidad de soluciones,
pues una vez lleguemos a un óptimo local, normalmente repetirá movimientos de intercambio
de forma indefinida, ya que estos no cambian el valor de la función objetivo, y son
aceptados por el criterio de Metrópolis.

Establecer una prioridad entre los tres operadores de vecindad daría como resultado un
algoritmo muy similar a la búsqueda local, que seguiría teniendo los mismos problemas.
Por lo tanto, centraremos nuestro esfuerzo en buscar una función objetivo que nos
permita una mayor exploración. No obstante, hemos de tener en cuenta que el algoritmo
debe seguir convergiendo a un óptimo local, por lo que no nos vale cualquier función.

Es posible encontrar algunos trabajos sobre MCP que involucran el enfriamiento simulado.
Sin embargo, se suelen basar en una representación y una estructura diferentes a las
consideradas en este problema, siendo imposible trasladarlos completamente a este caso,
aunque sí pueden traerse algunas de las ideas principales. En el caso de este trabajo,
se ha implementado un algoritmo que utiliza las nociones básicas de enfriamiento simulado
para ver sus diferencias con la búsqueda local, y un segundo algoritmo que recoge algunas
ideas de un artículo sobre el problema.

\subsection{Primer algoritmo}

Este algoritmo es una adaptación de una búsqueda local a un enfriamiento simulado, utilizando
una función objetivo basada en el tamaño de los cliques. En concreto, el valor de cada clique
es su tamaño más el número de vértices que contiene el conjunto $C_0$ dividido por el número
de vértices totales.
\[ f(C) = |C| + \frac{|C_0|}{N} \]
De esta forma, conseguimos que cliques de mayor tamaño tengan siempre un valor mayor que
aquellos con menor tamaño, lo que garantiza la convergencia a un óptimo local. En caso
de empate, utilizamos el tamaño del conjunto $C_0$ para determinar el mejor, pues, como
hemos discutido con anterioridad, cuanto mayor sea $C_0$ más puede crecer el clique.

Para el entorno, he considerado movimientos \textit{add}, \textit{swap} y \textit{drop},
sin priorizar ninguno de ellos. Se tomarán en orden aleatorio hasta encontrar uno que
mejore la función objetivo o satisfaga el criterio de Metrópolis.

Los valores de temperatura han sido inicializados a $T_{\text{inicial}} = 1,
T_{\text{final}} = 0.001$, con un mecanismo de enfriamiento geométrico, consistente
en multiplicar la temperatura por una constante $\beta$, fijada a $\beta = 0.99$.
Una vez se alcance una temperatura menor que la final, completamos el mejor clique
encontrado añadiendo tantos nodos como sea posible (aunque lo más probable es que
no se añada ninguno), eligiendo dichos nodos por mayor número de adyacencias.
Finalmente, el algoritmo devuelve el clique y finaliza.

El algoritmo trabaja siempre partiendo del clique vacío. No obstante, puede ser
adaptado fácilmente para que comience la exploración desde cualquier clique, lo
que nos permitiría combinarlo con otros algoritmos para obtener técnicas híbridas.

Vemos una descripción del algoritmo en pseudocódigo.

\begin{algorithm}[H]
\caption{Enfriamiento Simulado}
  \begin{algorithmic}
    \State $T = 1$
    \State $T_{\text{final}} = 0.001$
    \State $\beta = 0.99$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \State Entorno = $C_0 \cup C_1 \cup$ Drops
      \Repeat
        \State Sacar un clique del entorno, calcular $\Delta F$.
        \If{$\Delta F \geq 0$}
          \State Aceptar solución.
          \State Salir del bucle interno.
        \Else
          \State Aceptar solución con probabilidad $e^{\nicefrac{\Delta F}{T}}$.
          \State Salir del bucle interno si se acepta la solución.
        \EndIf
      \Until{Entorno $= \emptyset$.}
      \State $T = T \times \beta$
    \Until{$T < T_{\text{final}}$}
    \State{Ampliar mejor clique encontrado y devolver el resultado.}
  \end{algorithmic}
\end{algorithm}

\subsection{Segundo algoritmo}

En el segundo algoritmo, se han adaptado las ideas de X. Geng, J. Xu, J. Xiao y L. Pan,
que propusieron un algoritmo de enfriamiento simulado para MCP. Dicho algoritmo sigue
un enfoque distinto al de este problema, pues intenta buscar cliques de un tamaño
predeterminado, explorando el espacio de soluciones hasta que lo encuentra, o hasta
llegar al criterio de parada. Se basa en una representación por permutaciones del
vector de vértices, y va realizando intercambios de dos vértices, de tal forma que
uno sale del subgrafo y otro entra en él, siempre que la función objetivo mejore o
se satisfaga el criterio de Metrópolis. En este caso, en lugar de ir moviéndose entre
cliques, se consideran grafos de tamaño fijo, que se modificarán con el objetivo de
alcanzar un clique. Esto permite definir como función objetivo el número de aristas
que le faltan al grafo para ser un clique.

Para poder adaptarme a este enfoque, he tenido que diseñar un algoritmo que se moviera
entre grafos que no fueran un clique. He utilizado los mismos tres operadores \textit{add, swap}
y \textit{drop}, pero en este caso, he permitido añadir cualquier nodo al clique o
intercambiar dos nodos cualesquiera, sin necesidad de respetar la estructura de clique.
La exploración del nuevo entorno se hace igual que en el caso anterior, de forma aleatoria.

Al principio tomé la mismo función objetivo que la propuesta en el artículo, consistente
en el número de aristas necesarias para que el grafo sea un clique. Sin embargo, esta
función no asegura una convergencia a soluciones de calidad; en particular, es ajena al
tamaño de los cliques. Por esto, he usado la longitud de los grafos para corregir esta,
restándola al número de aristas restante. Así, tenemos una función objetivo que es menor
cuanto mayor es el grafo, y cuanto más se parece a un clique.

Una vez definida la función objetivo, el algoritmo explora el entorno y toma un elemento
aleatorio hasta que la función objetivo es menor, o hasta que se acepta el criterio de
Metrópolis. Como ahora no trabajamos con cliques, el grafo que obtenemos será reducido
a un clique, para lo que eliminaremos nodos uno a uno hasta que el resultado sea un clique.
Eliminaremos el nodo que menos adyacencias tenga. El clique obtenido no sustituye al grafo
que tengamos, sino que se compara con el mejor clique obtenido hasta el momento, reemplazándolo
si su longitud fuera mayor. Después del algoritmo continua explorando el entorno del
grafo actual, repitiendo el método descrito.

He vuelto a tomar los valores $T_{\text{inicial}} = 1, T_{\text{final}} = 0.001,
\beta = 0.99$ para los parámetros del algoritmo. Una vez finaliza la fase de enfriamiento,
vuelvo a añadir tantos nodos como sea posible al mejor clique encontrado, mediante un algoritmo
\textit{greedy} que prioriza los nodos con más adyacencias, devolviendo el clique resultante.



\section{Búsquedas multiarranque}

Las búsquedas multiarranque son un tipo de búsqueda local, que intentar salir de óptimos
locales reiniciando la búsqueda para tomar otra solución de partida, buscando explorar
una región distinta del espacio de soluciones. Dicha reinicialización de la búsqueda será
la clave para distinguir entre búsquedas multiarranque, y podemos distinguir entre las siguientes:

Búsqueda multiarrranque básica, que genera una solución inicial aleatoria y explora su entorno
mediante búsqueda local, repitiendo el proceso hasta que se satisfaga una condición de parada.
Es el método más sencillo, que no utiliza ningún tipo de información del problema, y equivale
a aplicar una búsqueda local múltiples veces sobre distintas soluciones aleatorias de partida.

Métodos constructivos de la solución inicial, donde esta varía en cada iteración. En este caso,
la solución inicial se obtiene mediante una construcción, intentando conseguir soluciones de
partida que sean de calidad. Intentaremos que las soluciones sean distintas en cada iteración,
por lo que el proceso de construcción será usualmente aleatorizado. Una vez se tenga la solución
inicial, se aplica búsqueda local, repitiendo hasta satisfacer una condición de parada,
normalmente un número de iteraciones fijo de antemano.

Métodos basados en la modificación del óptimo encontrado, en los que el óptimo local se somete
a una perturbación, dando lugar a una nueva solución de partida. Con esto utilizamos una
solución ya calculada para proporcionar una nueva solución de partida, con la que intentaremos
mejorar la calidad de la solución anterior. Nuevamente, repetiremos el proceso hasta alcanzar
una condición, que habitualmente será un número de repeticiones dado.

En este trabajo he considerado dos algoritmos de este tipo; uno basado en construcción de
la solución inicial, el algoritmo GRASP (\textit{Greedy Randomized Adaptative Search Procedure}),
y otro basado en modificaciones, el algoritmo ILS (\textit{Iterated Local Search}).
Vamos a detallarlos.

\subsection{GRASP}

El algoritmo GRASP, o \textit{greedy} aleatorizado, es un algoritmo multiarranque que consiste
en repetir una fase de construcción de una solución, seguida de una búsqueda local en el entorno
de dicha solución, hasta que se alcance una condición, que suele ser un límite de iteraciones
o de tiempo de ejecución. El un algoritmo sencillo de programar, y su capacidad para obtener
buenas soluciones está ligada a si los algoritmos \textit{greedy} y la búsqueda local ofrecen
buenos resultados sobre el problema, pues está fundamentado en ellos. Fue introducido formalmente
en 1989 (Feo, Resende), aunque la idea había sido descrita en 1987.

La construcción de la solución inicial sigue un procedimiento \textit{greedy}, en el cual,
en lugar de proporcionar un único candidato como se haría en un algoritmo \textit{greedy}
clásico, se proporcionan varios de los mejores, y de entre estos, elegiremos uno al azar.
El número de candidatos a considerar puede dejarse como parámetro, o fijarse de antemano,
quedando la decisión en manos del programador. Nótese que si el número de candidatos es
$1$, el algoritmo será un \textit{greedy} puro.

Esta técnica se utiliza para proporcionar diversidad, pues esta se pierde al tomar soluciones
iniciales generadas por algoritmos voraces. Así, seguimos obteniendo buenas soluciones de
partida, a la vez que estas difieren lo suficiente como para explorar una región amplia del
espacio de soluciones.

Una vez construída la solución inicial, se explora su entorno siguiendo una búsqueda local,
hasta alcanzar un óptimo local. Una vez alcanzado, se compara la solución con la mejor obtenida
hasta el momento, se actualiza si es necesario, y se comienza de nuevo el algoritmo.
Se repetirá el proceso hasta satisfacer una condición de parada.

\subsubsection{GRASP en MCP}

El aspecto fundamental de este algoritmo es la construcción de la solución inicial.
Podemos valorar los elementos del conjunto de candidatos de distintas formas, lo que
dará lugar a distintas soluciones de partida. Por lo demás, el algoritmo se basa en
una búsqueda local, que hemos discutido con anterioridad.

\subsubsection{Algoritmo implementado}

Como se acaba de mencionar, el aspecto fundamental de este algoritmo es la generación de
la solución inicial. Para ello, he tomado la lista de candidatos, $C_0$, y la he ordenado
por número de adyacencias en el grafo, en orden descendente. Una vez ordenada, tomo la
mitad superior como conjunto de candidatos, y hago una elección aleatoria entre los nodos,
en la que todos tienen la misma probabilidad de ser elegidos. El proceso se repetirá hasta
que $C_0$ sea vacío.

La fase de búsqueda local utiliza los dos métodos ya implementados, lo que da lugar a
dos versiones del algoritmo, en las que solo varía la búsqueda local. Como estos métodos
no se detienen en un óptimo, sino que necesitan un número de iteraciones máximo, he
establecido como límite el número de vértices del grafo, para que se adapte al tamaño
de cada problema.

Este proceso se repetirá un número determinado de iteraciones, que se pasará como parámetro.
Para este caso se ha fijado a $30$ en todas las instancias disponibles. Almacenaremos la
mejor solución obtenida, que será la que el algoritmo devuelva al final.

Vemos el pseudocódigo del algoritmo y de la generación de soluciones iniciales.

\begin{algorithm}[H]
\caption{GRASP}
  \begin{algorithmic}
  \Repeat
    \State Obtener solución inicial.
    \State Aplicar búsqueda local a la solución inicial.
    \State Actualizar mejor solución.
  \Until{Se alcance el número de iteraciones.}
  \State{Devolver mejor solución obtenida.}
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Generación de soluciones aleatorias}
  \begin{algorithmic}
    \State $Clique = \emptyset$
    \State $C_0 =$ vértices
    \Repeat
      \State Ordenar $C_0$ por adyacencias.
      \State Tomar la mitad superior de $C_0$.
      \State Añadir un elemento aleatorio a $Clique$.
      \State Recalcular $C_0$.
    \Until{$C_0 = \emptyset$}
    \State Devolver $Clique$
  \end{algorithmic}
\end{algorithm}


\subsection{ILS}

La búsqueda local iterada, o ILS (del inglés, \textit{Iterated Local Search}), es
un algoritmo de búsqueda local multiarranque basado en la perturbación de soluciones
como método para obtener diversidad. Fue propuesta en 1998 por Thomas Stützle,
y desde entonces se utiliza en la resolución de distintos problemas, entre los
que se encuentra el problema del clique máximo.

El algoritmo ILS requiere de cuatro componentes principales: una solución inicial,
un algoritmo de mutación de soluciones, un método de búsqueda local, y un criterio
de aceptación. Definiendo estos cuatro componentes en un problema, estaremos en
condiciones de aplicar el algoritmo.

El funcionamiento general de este tipo de algoritmos es el siguiente: primero, se
toma la solución inicial y se le aplica búsqueda local, hasta llegar a un óptimo local.
Seguidamente, se le aplica una mutación a la solución obtenida, que nos permite crear
una nueva solución inicial a la que volver a aplicar búsqueda local. Una vez finalizada
esta segunda búsqueda local, se usa el criterio de aceptación para ver si reemplazamos
la solución anterior con la obtenida. Este proceso mutación-búsqueda local-aceptación
se repetirá hasta que se satisfaga un criterio de parada. Finalmente, el algoritmo
devuelve la mejor solución encontrada.

Este modelo de ILS es el más básico que existe, pero no es el único. Podemos utilizar
un modelo basado en poblaciones, donde a cada elemento se le aplica ILS y estos se
combinan de alguna forma para una mayor exploración del espacio de soluciones, o el
modelo $(\nu + \lambda)$, donde, partiendo de $\nu$ soluciones iniciales, generamos
$\lambda$ hijos a partir de ellas mediante mutación, que compiten para pasar a la siguiente fase.

También es posible establecer diferencias en el criterio de aceptación. Si bien el
método más usual es tener una función objetivo, pueden utilizarse otros, como una
selección aleatoria, una selección basada en combinaciones, o una basada en probabilidades,
en la que podría utilizarse el algoritmo de Metrópolis, por ejemplo.

\subsubsection{ILS en MCP}

Es sencillo construir una búsqueda local iterada para el problema del clique máximo,
partiendo de un algoritmo de búsqueda local existente. Para ello, son necesarios un
criterio de aceptación, una solución inicial y una función de mutación.

\subsubsection{Algoritmo implementado}

Se ha implementado un algoritmo que sigue la filosofía de la búsqueda local iterada
básica basado en el propuesto por A. Grosso, M. Locatelli y W. Pullan, que usa el
algoritmo de búsqueda local DLS, si bien se propusieron algunas modificaciones que
aquí no se han tenido en cuenta. En mi caso, además de DLS, he utilizado el otro
algoritmo de búsqueda local implementado, para comparar las diferencias entre ambos
al ser utilizados por ILS. Vemos a continuación la función de mutación y el criterio
de aceptación utilizados.

El algoritmo para mutar un clique consiste en tomar un nodo que no se encuentre en él,
eliminar del clique todos los nodos que no estén conectados a él, y finalmente añadir
dicho nodo al clique. Con este método conseguimos una solución de partida que se encuentra
en una zona distinta del espacio de soluciones, a la vez que usamos información de la
iteración anterior para movernos por soluciones que serán potencialemente de calidad.

La función de aceptación se queda siempre con el último clique obtenido tras la búsqueda local.
Tras valorar si quedarme con la última o con la mejor encontrada, decidí hacer lo primero,
para favorecer la diversidad en las soluciones. No obstante, tendremos almacenada la mejor
solución, al ser el valor de salida del programa.

Dado que las dos búsquedas locales implementadas requieren de un límite como criterio de
parada, he fijado dicho límite al número de vértices del grafo, para que se adapte al
tamaño de cada problema. Además, el criterio de parada del algoritmo también es un número
de iteraciones, que ha sido $30$ para todas las instancias.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ILS}
  \begin{algorithmic}
    \State Generar solución inicial.
    \State Aplicar búsqueda local.
    \Repeat
      \State Modificar solución.
      \State Aplicar búsqueda local a la solución obtenida.
      \State Actualizar la mejor solución, si es necesario.
    \Until{Se alcance el número de iteraciones.}
    \State{Devolver mejor solución obtenida.}
  \end{algorithmic}
\end{algorithm}

\section{Algoritmos de colonia de hormigas}

Los \textbf{algoritmos de colonia de hormigas} o ACO (del inglés, \textit{Ant Colony Optimization})
son una técnica de adaptación social, que se basa en el comportamiento de las colonias de
hormigas, para tratar de encontrar caminos en grafos. Para ello, utilizará un recurso
que emula a las feromonas que emiten las hormigas cuando se desplazan.

Las hormigas utilizan este rastro de feromonas para guiarse, pues poseen unos receptores
capaces de captar la intensidad de dicho rastro. Dado su pésimo sentido de la vista,
el uso de las feromonas es vital para que las hormigas se desplacen y sean capaces de
localizar fuentes de alimento, volver al hormiguero, y que el resto de la colonia también
sea capaz de llegar a la comida, siguiendo el rastro que las propia hormigas dejan.

Este rastro de feromonas no permanece de forma indefinida en el ambiente, sino que
sufre un proceso de evaporación constante. De esta forma, caminos más cortos tenderán
a una mayor concentración de feromonas, lo que incrementará el tránsito de hormigas.
Por otra parte, los caminos más largos recibiran menos aporte de feromonas, lo que a
la larga hará que dejen de ser visitados.

La elección por parte de una hormiga del camino que recorrer se fundamenta en un
criterio probabilístico. La hormiga tiende a recorrer caminos en los que el rastro
de feromona es mayor, aunque podrá ir por otros donde el rastro no sea tan intenso.

Su fundamentación teórica hace que sea un algoritmo muy eficaz para problemas que
requieren de construcción de caminos, como el problema del viajante de comercio.
En general, son algoritmos que funcionan bien cuando trabajan sobre estructuras
similares a los grafos.

Este comportamiento será trasladado a la optimización por colonia de hormigas,
mediante la construcción de hormigas artificiales. Tendremos un rastro de feromona
artificial, que simula el que dejan las hormigas al recorrer un camino. Es posible
complementar el uso de las feromonas con información heurística del problema,
con el objetivo de crear un mecanismo probabilistico de construcción de soluciones
que no solo se base en feromonas, sino que use más información disponible.

Las hormigas serán la encargada de ir recorriendo el grafo, utilizando la información
de la que dispone para decidir a qué nodo moverse mediante una función de probabilidad.
Los nodos que compongan una solución serán reforzados con un aumento de feromonas, y
se hará de forma que mejores soluciones reciban más cantidad de feromona.
Se utiliza también un mecanismo de evaporación de feromona simulando al que ocurre en
la naturaleza, que evita un crecimiento ilimitado de la misma. Para esto, se reducirán
todos los rastros de feromona eliminando un parte de su valor actual, usualmente un
porcentaje fijo. En la práctica, esto se traduce en evitar un estancamiento del algoritmo,
debido a que los nodos más visitados tendrían altas probabilidades de repetirse en la
siguiente solución.

Por norma general, se lanzarán un número determinado de hormigas artificiales independientes,
las cuales generan una solución cada una. Entre ellas, se toma la mejor, y esta será la
que cambie los niveles de feromona. Este proceso se repite hasta que se satisfaga una
condición de parada, que suele ser un número de iteraciones o un límite temporal.

Existen numerosas variantes de las colonias de hormigas, dependiendo de la función de
probabilidad, la actualización de feromonas, etcétera. En este trabajo he tomado el
algoritmo más clásico, sin entrar en otros que requerirían de mayor experimentación
para hacer ajustes sobre los parámetros.

También es posible hibridar este método con otros, usualmente un algoritmo de búsqueda
basado en entornos, como una búsqueda local o un enfriamiento simulado. La hibridación
se lleva a cabo aplicando el método a cada hormiga de la colonia una vez ha construído su solución.

\subsection{ACO en MCP}

Al ser el problema del clique máximo un problema de grafos, los algoritmos de colonias
de hormigas son fácilmente implementables, y se pueden esperar buenos resultados en su
ejecución. Si bien en MCP no tratamos de recorrer un grafo, como se haría en el problema
del viajante de comercio, el concepto es adaptable para trabajar con conjuntos de candidatos
sobre los cuales realizamos una acción, como un \textit{add} o un \textit{swap}.

En este trabajo, he considerado dos algoritmos de colonias de hormigas clásicos,
lanzando una colonia de hormigas durante un número determinado de iteraciones y
reforzando el nivel de feromonas en las soluciones de calidad. La evaporación se
realiza reduciendo un porcentaje de feromona, fijo en todas las iteraciones.
La diferencia entre ambos algoritmos reside en la función de probabilidad;
mientras que uno de ellos utiliza solo las feromonas, el segundo complementa
el uso de las feromonas con información del grafo.

\subsection{Primer algoritmo}

El primer algoritmo implementa una colonia de hormigas básica, en la que un número
fijo de hormigas crean una solución cada una, y la mejor es la que se tiene en cuenta
para modificar los niveles de feromona. He considerado únicamente movimientos \textit{add},
por lo que las hormigas irán recorriendo los nodos del conjunto $C_0$ hasta que
este sea vacío.

Cada hormiga comenzará desde un clique vacío y añadirá nodos del conjunto $C_0$ según
una regla probabilística, que consiste en dar a cada nodo del conjunto una probabilidad
proporcional a su feromona, normalizándola para obtener un valor entre $0$ y $1$, y
conseguir que la suma de todas las probabilidades de los nodos de $C_0$ sea $1$.
Para ello,  solo hemos de dividir el valor de la feromona de un nodo por la suma de
los valores de los nodos de $C_0$. Inicialmente, la probabilidad será la misma para
cada nodo,  por lo que no damos ventaja a ninguno y dejamos que sea el proceso el
que determine los mejores nodos.

El proceso se repite hasta que la hormiga finaliza la creación de su clique, dando
paso a la siguiente, que crea uno distinto, y así hasta que todas las hormigas completen
el suyo. Cada vez que una hormiga finaliza, compara su clique con el mejor obtenido
en esa iteración, sustituyéndolo de ser necesario. Así, tendremos siempre el mejor
clique creado por la colonia a lo largo de cada iteración.

Una vez finalizado el trabajo de todas las hormigas, se produce la evaporación de
feromona, consistente en multiplicar los valores en cada nodo por una constante $\beta$.
Seguidamente, se aumentan los niveles de feromona en los nodos de la mejor solución,
multiplicando el valor de esta por un valor $\alpha$. Este valor dependerá del tamaño
del clique encontrado, siendo mayor cuanto más tamaño tiene el clique. Así, conseguimos
dar más peso a soluciones de más calidad.

El proceso se repite un número fijado de iteraciones. Una vez terminadas todas las
iteraciones, el algoritmo finaliza y devuelve la mejor solución encontrada.

Se han fijado los valores $\beta = 0.925$, $\alpha = (5 \times |C| + N) / N$, donde
$|C|$ es el tamaño del clique encontrado, y $N$ es el número de vértices del grafo.
Para fijarlos, me he valido de la experimentación, tomando aquellos que daban mejores
resultados en un conjunto reducido de instancias. No obstante, las diferencias
eran mínimas entre todos los valores probados.

El número de hormigas en cada iteración ha sido fijado a $50$, efectuándose un total
de $40$ iteraciones.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ACO 1}
  \begin{algorithmic}
    \State $T_{\text{final}} = 0.01$
    \State Inicializar constantes $\alpha, \beta$.
    \State $Mejor Clique = []$.
    \Repeat
    \State $Hormigas = 0$.
      \State Establecer el mejor clique de la colonia al clique vacío.
      \Repeat
        \State $Clique = []$
        \State Añadir vértice aleatorio al clique
        \State Calcular $C_0$
        \Repeat
          \State Calcular probabilidades de los nodos en $C_0$. Normalizar.
          \State Elegir un nodo según la probabilidad y añadirlo a clique.
          \State Recalcular $C_0$.
        \Until{$C_0 = \emptyset$}
        \State Actualizar el mejor clique de la colonia si es necesario.
        \State $Hormigas = Hormigas + 1$.
      \Until{$Hormigas = $ límite hormigas}
      \State Actualizar $Mejor Clique$ si es necesario.
      \State Evaporar feromona.
      \State Aportar feromona a los nodos del mejor clique de la colonia.
      \State $i = i+1$.
    \Until{$i = limite$}
    \State{Devolver mejor clique encontrado.}
  \end{algorithmic}
\end{algorithm}


\subsection{Segundo algoritmo}

Este algoritmo toma algunas de las ideas de X. Xu, J. Ma y J. Lei, que trata de
mejorar el ACO básico considerando información relativa al clique para calcular
las probabilidades de elegir un nodo. La única diferencia con el anterior está
dicho cálculo, para el que utilizaremos una técnica de enfriamiento simulado,
además del uso de los valores de feromona.

La probabilidad se compone de dos partes: la primera de ellas es idéntica a la
anterior, un valor entre $0$ y $1$ obtenido de las feromonas de cada nodo en $C_0$,
normalizando para que la suma total sea $1$. Además, sumaremos un valor que depende
del grado de cada nodo, y estará multiplicado por una temperatura, de forma que la
importancia de este término desciende en el tiempo. La fórmula para el cálculo
de la probabilidad queda de la siguiente forma:
\[ p(v_i) = \frac{\tau(v_i)}{\sum_{v_j \in C_0} \tau(v_j)} + T \frac{D(v_i)}{N} \]
donde $\tau(v_i)$ es el valor de la feromona en el nodo $v_i$, $T$ es la temperatura,
$N$ el número de nodos del grafo, y $D(v_i)$ es el grado de $v_i$. Una vez calculadas
todas las probabilidades de los nodos de $C_0$, las normalizaremos para tener valores
entre $0$ y $1$ y que la suma siga siendo $1$.

La temperatura sigue un esquema de descenso geométrico similar al utilizado en los
algoritmos de enfriamiento simulado, en los que la temperatura se multiplica por
una constante $\gamma$ en cada iteración. Dicho valor se ha fijado a $\gamma = 0.95$.
Los valores de $\alpha$ y $\beta$ siguen siendo los mismos que en el algoritmo anterior,
al igual que el número de hormigas y de iteraciones, que son $50$ y $40$ respectivamente.

Puesto que solo cambia la función del cálculo de la probabilidad, no incluyo pseudocódigo
de este algoritmo, por ser similar al anterior.

\section{Algoritmos genéticos}

Los algoritmos genéticos entran dentro de la llamada \textbf{computación evolutiva},
que está compuesta por modelos de evolución basados en poblaciones. Se basan en
los procesos evolutivos que están presentes en la naturaleza, en los que dos padres
combinan sus genes para producir hijos (usualmente dos), los cuales presentan
características de ambos. Las diferencias entre generaciones pueden llevar a nuevas
configuraciones que devengan en una mejor adaptación al entorno. Esto, en el ámbito
que nos encontramos, se traduce en cambios que nos lleven mejores soluciones, pues
estas se adaptan mejor al problema.

En los algoritmos genéticos, las poblaciones estarán formadas por soluciones al
problema, que combinaremos dos a dos para producir descendientes que intenten mejorar
a sus progenitores. Esta combinación de soluciones se produce mediante el llamado
\textbf{operador de cruce}, que emula cómo los cromosomas se mezclan para producir
una nueva generación. Este operador dependerá del problema y no tiene por qué ser único.
El requisito fundamental es que se tome información de ambos progenitores para crear
a sus descendientes.

En la naturaleza, es posible que al combinar dos individuos se produzca una mutación,
con lo cual el hijo tendría una característica que no ha adquirido de ninguno de sus
padres, y que podría conllevar una ventaja o un perjuicio para el mismo. Esta técnica
se reproducirá en los algoritmos genéticos, incluyendo la posibilidad de que una
solución mute al ser generada. Al igual que el operador de cruce, las mutaciones
pueden seguir distintos enfoques, aunque se suele requerir que introduzcan modificaciones
significativas en los elementos de la población.

Controlaremos el cruce entre individuos y las mutaciones de sus descendientes con
parámetros que establezcan la probabilidad de que ambos sucesos ocurran. Para el
cruce, seleccionaremos dos individuos que o bien generarán descendientes, o bien
pasarán directamente a la siguiente generación. En caso de generar descendientes,
cada uno de ellos podrá ser mutado en el momento de su creación.

Existen distintas formas de seleccionar a los padres. El muestreo puede ser aleatorio,
se puede dar mayor probabilidad de combinarse a los mejores, etc. No hay restricción
en cuanto al número de veces que se puede reproducir un elemento, si bien podría
establecerse de considerarse necesario.

De igual forma, existen diversos métodos para crear una nueva generación. Una de
ellas sería que los hijos sustituyan a los padres, el llamado modelo generacional.
En este caso, se crea una nueva población en cada iteración del ciclo. Es posible
incluir elitismo, de forma que la mejor solución de la población pasa siempre a
la siguiente generación, lo que nos permite conservarla siempre sin necesidad de
almacenarla explícitamente. Otro modelo es el llamado estacionario, en el cual
se eligen dos padres, que generan dos hijos, y estos compiten para pasar a la
siguiente generación, pudiendo hacerlo con los padres o con la población en general.
Este modelo ya es elitista, luego no necesita introducir elitismo explícitamente.

\subsection{Genéticos en MCP}

Implementar un algoritmo genético para el problema del clique máximo se basa en
considerar operadores de cruce y mutación apropiados, esto es, que mantengan la
estructura de clique. A priori, no podemos afirmar que la combinación arbitraria
de dos soluciones o la mutación produzcan cliques, por lo que estos operadores
deben ser muy específicos o ser rectificados de alguna forma.

Una vez tengamos estos operadores, la ejecución del algoritmo consiste simplemente
en ir obteniendo nuevas generaciones hasta un criterio de parada determinado.
En este caso, para el algoritmo implementado, se ha establecido un número fijo de
iteraciones.

\subsection{Algoritmo implementado}

El algoritmo genético implementado se basa en un modelo estacionario, en el que
los dos descendientes compiten con sus padres para entrar en la nueva generación.
Al principio, se creará una población de soluciones de forma aleatoria mediante
un algoritmo \textit{greedy}, y a partir de aquí se irán generando nuevas soluciones.

El operador de cruce opera de la siguiente forma: dados dos padres, se toman aquellos
nodos comunes en ambos, y estos estarán presentes en ambos hijos. Seguidamente,
tomaremos el conjunto de nodos presentes en uno de los dos padres, y los distribuiremos
entre los dos hijos de forma aleatoria y equiprobable.

Una vez tengamos los hijos, procedemos a mutarlos con la probabilidad dada. El
algoritmo de mutación toma dos valores aleatorios entre $0$ y el número de nodos
del grafo, y cambia los nodos del intervalo que forman, quitándolos del hijo si
pertenecen a él, e introduciéndolos si no lo hacen.

Como no tenemos garantizado que los hijos sean cliques antes o después de la mutación,
los reduciremos a un clique eliminando nodos hasta que el conjunto restante sea un
clique. Una vez reducido, lo ampliaremos hasta que el clique sea maximal.
Ambos procesos de reducción y ampliación se hacen de forma aleatoria, para evitar
añadir complejidad computacional al algoritmo y hacer que sus tiempos de ejecución
se eleven. Podríamos haber tomado cualquier otro método basado en el información del
grafo, como ordenar por número de adyacencias.

La población inicial se ha tomado con un tamaño de $50$ individuos, con probabilidad
de cruce de $1$ y probabilidad de mutación de $0.1$, un valor alto para lo usual,
fijado así para introducir diversidad en la población. El criterio de parada es un
límite de iteraciones, que se ha fijado a $40$ en las ejecuciones realizadas.
Estos parámetros pueden ser modificados para evaluar la funcionalidad del algoritmo
bajo otras circunstancias.

[Pseudocódigo aquí]

\section{Algoritmos meméticos}

Los algoritmos meméticos son el resultado de la combinación de algoritmos meméticos
con búsqueda local. Tratan de aprovechar la buena capacidad de exploración de los
algoritmos genéticos, y combinarla con la explotación de soluciones de las técnicas
de búsqueda local.

El diseño de estos algoritmos queda muy abierto, y por lo general, suele ser necesario
adaptarlos de una forma u otra dependiendo del problema. Suelen ser algoritmos específicos,
que aprovechan alguna característica en concreto del problema.

Entre las diversas decisiones que hay que tomar, una de las más relevantes es el
proceso de búsqueda local a considerar y cuándo aplicarlo. Podemos elegir cualquier
técnica por trayectorias simples, desde una búsqueda local básica a una busqueda
tabú, y podemos aplicarlas a toda la población o a una parte, en distintas
fases del algoritmo.

\subsection{Meméticos en MCP}

Debido a que disponemos de técnicas de búsqueda local y algoritmos genéticos, la
implementación de un algoritmo memético consiste en tomar las decisiones correspondientes
con respecto a la hibridación de ambas técnicas.

\subsection{Algoritmo implementado}

En este trabajo, he optado por una combinación básica de dos algoritmos ya implementados,
el algoritmo genético y la búsqueda local. De esta forma, se mantiene la estructura
de algoritmo genético estacionario, introduciendo una búsqueda local al final de
la creación de la nueva generación, lo que nos permite explorar su entorno antes de
pasar a la siguiente.

El desarrollo del algoritmo es muy simple, pues utiliza como base el algoritmo
genético introducido anteriormente. Utiliza el mismo operador de cruce y mutación,
y añade una búsqueda local después de que los hijos sean reducidos y ampliados.

Para esta búsqueda local, he utilizado los dos métodos implementados para este trabajo,
lo que da lugar a dos algoritmos meméticos. Como parámetros, he tomado las mismas
probabilidades de cruce y mutación, $1$ y $0.1$, y he establecido el límite de la
búsqueda local en un octavo del número de nodos del grafo, para explorar únicamente
la zona del espacio de soluciones más cercana a cada elemento de la población.  
