%************************************************
\chapter{Algoritmos}\label{ch:algoritmos}
%************************************************

En este capítulo se tratarán los diferentes algoritmos considerados en el trabajo,
hablando de la metaheurística en la que se engloban, viendo cómo esta se adapta al
problema, y finalmente explicando las técnicas consideradas.

\section{Consideraciones iniciales}

Antes de describir cada algoritmo, vamos a ver consideraciones más generales sobre el problema, que serán
utilizadas en los algoritmos que se implementen. Discutiremos la representación de las soluciones, el
operador de vecindad, la función objetivo y la inicialización del programa.
% Representación de la solución. Inicialización del programa (lectura). Operador vecino. Entorno. Función objetivo.

Cada solución del problema será un clique que se encuentre dentro del grafo. Este clique estará representado
por los nodos que contiene, de forma que las soluciones serán conjuntos de la forma $\{x_0, \dots, x_p\}$,
donde cada elemento $x_i$ representa un nodo del grafo, que está identificado de forma única por un índice.

La función para medir la calidad de una solución (función objetivo) será el tamaño de cada clique, si bien
se considerarán algunas variantes en ciertos algoritmos. No obstante, como el objetivo final es obtener un clique
del mayor tamaño posible, es lógico que el factor de peso en cualquier función objetivo sea el tamaño del mismo.

Como operador de vecino tenemos tres distintos, los cuales aplicados sobre cada clique nos permitirán obtener su entorno.
Los vemos con más detalle:

\subsection{Operador \textit{add}}

El primer operador, al que llamaremos operador \textit{add}, consiste en añadir al clique un
nuevo nodo que conserve la estructura de clique, esto es, que esté conectado con todos los
nodos del clique. Usualmente tendremos calculado el conjunto de nodos que podemos añadir
a cada clique con el que estemos trabajando. Llamaremos a dicho conjunto $C_0$ o posibles adiciones.

Podemos ver el operador \textit{add} como una función encargada de añadir un nodo a un clique.
Supondemos que el nodo $x$ que añadimos está en el conjunto $C_0$, por lo que el grafo resultante
sigue siendo un clique.

\begin{algorithm}[H]
\caption{Operador \textit{add}}
  \begin{algorithmic}
  \Function{add}{clique, x}
    \State $clique = clique \cup x$
    \Return $clique$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Operador \textit{swap}}

El segundo operador, al que nos referiremos como \textit{swap}, consiste en intercambiar un
nodo del clique con uno de fuera, de forma que se siga manteniendo la estructura. Para ello,
el nodo que no pertenece al clique debe estar conectado con todos salvo uno de sus nodos,
que será el nodo que saldrá del clique. Nos referiremos a este conjunto de nodos como posibles
intercambios o $C_1$. Al igual que el anterior, también tendremos calculado dicho conjunto de
nodos para cada clique con el que trabajemos.

Al igual que el anterior, podemos ver el operador como una función que actúa sobre un grafo y
dos nodos, $in$, dentro del clique, y $out$, fuera de él. Nuevamente, suponemos que se mantiene
la estructura de clique tras realizar las operaciones.

\begin{algorithm}[H]
\caption{Operador \textit{swap}}
  \begin{algorithmic}
  \Function{swap}{clique, in, out}
    \State $clique = clique - in$
    \State $clique = clique \cup out$
    \Return $clique$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Operador \textit{drop}}

Finalmente, el tercer operador de vecino será el operador \textit{drop}, que consiste simplemente en quitar
un nodo del clique. En este caso no tenemos que preocuparnos por que el grafo resultante sea un clique,
pues siempre que eliminemos nodos de un clique el resultado seguirá siendo otro clique.

Viéndolo como una función, el funcionamiento sería el siguiente:

\begin{algorithm}[H]
\caption{Operador \textit{drop}}
  \begin{algorithmic}
  \Function{drop}{clique, x}
    \State $clique = clique - x$
    \Return $clique$
  \EndFunction
  \end{algorithmic}
\end{algorithm}


\subsection{Entorno}

Estos serán los tres operadores que utilicemos, que definirán el entorno de una solución, compuesto por
aquellas a las que se puede llegar mediante el uso de cualquiera de los tres, aunque no siempre se
usarán los tres a la vez. El operador \textit{add} es esencial, pues nos permite ampliar el tamaño de un
clique, por lo que siempre lo utilizaremos. Los otros dos operadores se usarán dependiendo del algoritmo,
siendo el operador \textit{swap} bastante frecuente, y el \textit{drop} menos frecuente. Debido a esto,
el entorno variará dependiendo de aquellos consideramos. Detallaremos en cada caso los operadores
considerados y las razones principales de su elección.

Pasamos ya a ver los algoritmos que se han incluido en este trabajo.

\section{Algoritmos \textit{greedy}}\label{greedy}

Los algoritmos voraces, o algoritmos \textit{greedy}, son aquellos que resuelven problemas tomando
las decisiones óptimas en cada instante. Esto no lleva necesariamente a un óptimo global, pero puede
aproximarlo de forma razonable en un periodo de tiempo generalmente muy pequeño. Este tipo de algoritmos
basan sus decisiones inmediatas en las que ya se han tomado, pero nunca en lo que podría suceder más
adelante.

Por lo general, en los algoritmos \textit{greedy} tendremos un conjunto de candidatos, una función
de selección, que se encarga de elegir al mejor candidato en cada momento, una función objetivo, que
da un valor a cada solución, una función de factibilidad, que elige los candidatos que se pueden incluir
en una solución, y una función que nos dice si tenemos una solución.

Este tipo de algoritmos suelen ser irreversibles, esto es, no se pueden deshacer elecciones ya hechas.
No obstante, existen varios tipos de algoritmos \textit{greedy}, en los que esta condición se relaja. Así,
distinguiremos entre algoritmos \textit{greedy} puros, relajados y ortogonales. En este trabajo se han
implementado dos algoritmos \textit{greedy}, uno puro y otro relajado.

\subsection{\textit{Greedy} en MCP}

En el problema del clique máximo, los algoritmos \textit{greedy} tienen dos enfoque principales:
o bien se parte de un conjunto vacío y se añaden vértices, respetando la estructura de clique,
hasta que no sea posible añadir más, o partimos del conjunto total de vértices y vamos eliminando
nodos hasta que el grafo obtenido sea un clique.

Los dos algoritmos \textit{greedy} que he implementado siguen el primer enfoque de los
mencionados anteriormente. Se diferencian principalmente en la elección del vértice que
se añade al clique, aunque en uno de ellos modificaremos también la estructura de entornos,
considerando intercambios además de adiciones.

A continuación se detallan en más profundidad los dos algoritmos implementados.

\subsection{Greedy básico}\label{greedy1}

Este algoritmo es una implementación propia, que trata de crear un algoritmo lo más
básico posible usando los conceptos esenciales de los algoritmos \textit{greedy}.
Comenzando desde un clique vacío, añade nodos al clique, respetando la estructura, hasta
que no se pueda añadir ninguno más. Para elegir el vértice que añadir, toma, de aquellos que
pueden añadirse, el que tiene mayor número de adyacencias, usando el operador \textit{add}.
Otras posibles opciones serían elegir un nodo aleatorio entre los disponibles o tomar aquel que
maximice el tamaño del conjunto $C_0$ al añadirse al clique.

Este algoritmo es irrevesible, pues los nodos que se añadan al clique no saldrán de él
en ningún caso.

Vemos a continuación el pseudocódigo del algoritmo.

\begin{algorithm}[H]
\caption{Greedy}
  \begin{algorithmic}
  \Function{greedy}{}
  \State $Clique = [ ]$
  \State $C_0 = $ Vértices
  \Repeat
    \State{Añadir $v \in C_0$ con más adyacencias}
    \State{Actualizar $C_0$}
  \Until{$C_0 = \emptyset$}
  \Return $clique$
  \EndFunction
  \end{algorithmic}
\end{algorithm}


\subsection{Greedy adaptativo}\label{greedy2}

En este algoritmo, se han seguido las ideas de Grosso, Locatelli y Della Croce,
\citep{grosso:2004} usando un algoritmo que nos permite deshacer, en cierta forma,
decisiones tomadas anteriormente. La idea es no solo considerar aquellos vértices
que pueden ser añadidos al clique, sino también tomar aquellos que pueden ser
intercambiados por uno del clique, es decir, usar operadores \textit{add} y \textit{swap}.

El criterio para elegir un nodo será el número de conexiones con el conjunto de
posibles adiciones al clique, buscando maximizar este número. Así, al añadir el
nodo al grafo, el tamaño del conjunto $C_0$ será el máximo de los posibles.
Como dicho tamaño es una cota superior para el número de nodos que se pueden
añadir al clique, nos interesa que sea lo más elevado posible.

Antes de empezar a considerar intercambios, queremos que el clique tenga un tamaño
mínimo,  por lo que al principio consideraremos solo movimientos \textit{add} hasta
alcanzar dicho tamaño. Se ha fijado el valor del tamaño mínimo en $4$ para todos
los grafos, a partir del cual se empiezan a considerar los intercambios y no solo las
adiciones. Detendremos el algoritmo una vez lleguemos a un clique maximal, esto es,
cuando el conjunto $C_0$ sea vacío. No obstante, se ha fijado un valor máximo de
intercambios para evitar que el algoritmo se prolongue durante mucho tiempo. De darse
el caso en el que el algoritmo se detiene por alcanzar dicho límite, es posible que
el clique que tengamos no sea maximal, por lo que será ampliado mediante movimientos
\textit{add} hasta que no sea posible añadir más nodos.

Para evitar repetición de intercambios, en el momento en el que se haga uno guardaremos
el nodo que sale del clique, para no tenerlo en cuenta en la siguiente iteración.
De no hacer esto, cabe la posibilidad de entrar en un bucle, en el que se
intercambien dos nodos de forma indefinida hasta que se alcance el criterio de parada.

Vemos a continuación el pseudocódigo de la parte adaptativa del algoritmo.

\begin{algorithm}[H]
\caption{Greedy adaptativo}
  \begin{algorithmic}
  \Function{greedy}{limite}
  \State $clique = [ ]$
  \State $C_0 = $ Vértices
  \State $C_1 = [ ]$
  \State $i = 0$
  \State $Swap = -1$
  \Repeat
    \State Tomar $v \in C_0 \cup C_1 - Swap$ que maximice adyacencias con $C_0$
    \If {$v \in C_0$}
      \State Añadir $v$ a $clique$
    \Else
      \State Hacer intercambio
      \State Actualizar $Swap$, $i += 1$
    \EndIf
    \State{Actualizar $C_0, C_1$}
  \Until{$C_0 = \emptyset$ o $i = limite$}
  \Return $clique$
  \EndFunction
  \end{algorithmic}
\end{algorithm}


\section{Búsqueda local}\label{busquedalocal}

Los algoritmos de búsqueda local son aquellos que se centran en el entorno de una
solución para buscar nuevas soluciones que sean mejores que la anterior. Dicho entorno
viene dado por aquellas soluciones a las que se puede llegar desde la solución de
partida mediante un \textbf{operador de vecindad}. Llamaremos a estas soluciones
\textbf{soluciones vecinas}.

Las distintas formas de recorrer el entorno y de aceptar soluciones vecinas dan
lugar a los distintos algoritmos de búsqueda local. El criterio de aceptación debe
ser monótono, pues queremos que conduzca a soluciones cada vez mejores, finalizando
en un óptimo local. La búsqueda local básica busca mejorar el resultado con un elemento
del entorno, terminando si este no existe y alcanzando un máximo local. Por tanto, se
basa en una mejora paulatina de las soluciones, hasta que no es posible encontrar
ninguna mejor.

Habrá ocasiones en las que la monotonía no se exija de forma obligada, para permitir
al algoritmo salir de óptimos locales. Debido a esto, existen algoritmos como el
enfriamiento simulado o la búsqueda tabú, que son más flexibles en esta condición.

La estructura de entornos también puede ser variable, lo que nos llevaría a una
búsqueda en entornos variables (VNS) o, nuevamente, a una búsqueda tabú.
Todo esto se hace con el objetivo de que nuestro  algoritmo sea capaz de escapar
de óptimos locales, y alcance el óptimo global.

Las técnicas de búsqueda local se utilizan no solo como heurísticas para resolver
problemas, sino como complementos de otras. Por ejemplo, pueden ser utilizadas junto
a los algoritmos genéticos para mejorar el conjunto de soluciones, o aplicarse después
de técnicas \textit{greedy} para explorar el espacio de soluciones de la solución
generada. También se usan en técnicas multiarranque como ILS o GRASP, que explicaremos
más adelante.

En este trabajo, se han implementado dos técnicas de búsqueda local, que difieren en
la estructura de entornos y en el método de elección de candidatos. Asimismo, se han
implementado dos algoritmos de enfriamiento simulado, y se han incorporado varias de
las técnicas mencionadas anteriormente en otros algoritmos. Estas serán detalladas en cada caso.

\subsection{Búsqueda local en MCP}

En la búsqueda local, las diferencias que hacen a los algoritmos distintos están en la estructura
de entornos y en elección de una solución vecina a la que desplazarse. Estas diferencias son
también las que existen entre los dos algoritmos implementados en este trabajo. Nos valdremos
de los operadores \textit{add, swap} y \textit{drop} como operadores de vecindad, si bien no
siempre los tendremos todos en cuenta.

En el primer algoritmo se consideran los tres movimientos para calcular el entorno.
Si bien esto rompe con la filosofía de que la búsqueda local debe ir a mejores soluciones,
la posibilidad de eliminar elementos del clique se incluye para evitar que estos algoritmos
sean similares a los \textit{greedy}, buscando favorecer una búsqueda en el entorno.

En el segundo algoritmo, solo se consideran movimientos \textit{add} y \textit{swap}.
En un principio, este algoritmo puede parecer similar al \textit{greedy} adaptativo
detallado anteriormente, aunque veremos que tiene varias diferencias fundamentales
con respecto a este.

Veámoslos en más detalle.

\subsection{1LS}\label{1ls}

Este algoritmo se basa en las ideas de Katayama, Hamamoto y Narihisa \citep{katayama:2005},
siendo una versión simplificada de su \textit{k-opt local search} para el caso $k = 1$.
El algoritmo \textit{k-opt} consiste en tomar todas las posibles combinaciones de $k$
movimientos para generar el entorno de un clique, y explorar este entorno siguiendo
diversas técnicas (en este caso, una búsqueda local). La versión considerada en este
trabajo toma $1$ como valor de $k$, por lo que nos referiremos al algoritmo por \textbf{1LS}.

Para crear el entorno, se han considerado los tres movimientos básicos de la búsqueda local,
\textit{add, swap} y \textit{drop}, dando distintas prioridades a cada uno de ellos. Como
nuestro objetivo es construir un clique del mayor tamaño posible, añadiremos vértices siempre
que podamos, tomando aquel que tenga más conexiones con el conjunto $C_0$ en caso de haber varios.
Cuando no sea posible, intentaremos hacer un swap, siempre que este nos lleve a un escenario
en el que podamos añadir más nodos al clique resultante. La elección de los nodos a intercambiar
se hace mediante la técnica del primer mejor, esto es, tomamos el primero que encontremos.
De no poder hacer ningún swap bajo estas condiciones, eliminaremos del clique el nodo que
tenga menos adyacencias con todos los nodos del grafo.

Para evitar que los nodos que eliminemos sean añadidos inmediatamente al clique, los iremos
acumulando en una lista tabú. Los nodos de esta lista no se tendrán en cuenta a la hora de
hacer un movimiento add, lo que nos asegura que el clique cambia, pues evitamos entrar en
un bucle en el que eliminamos un nodo y acto seguido lo volvemos a añadir al clique.
Esta lista tabú será vaciada en el momento en el que se realice un movimiento que no sea
quitar un nodo del clique, ya que nos habremos asegurado de que el clique incluye al menos
un nodo que no contenía antes de comenzar a eliminar nodos.

Este algoritmo no tiene un criterio de parada inducido por el entorno, pues siempre podremos
hacer alguno de los tres movimientos. Por tanto, es necesario establecer un límite, que este
caso, ha sido establecer un límite de swaps y drops a realizar a lo largo del algoritmo.
Una vez alcanzado este límite, el algoritmo finaliza, devolviendo el mejor clique encontrado.
Para evitar que el límite sea una constante común para todas las instancias, se ha establecido
en proporción al número de vértices del grafo, haciendo que el algoritmo se adapte al tamaño
de cada problema.

El hecho de considerar un criterio de elección sobre los nodos del conjunto $C_0$ y $C_1$ hace que
el orden del algoritmo sea $\mathcal{O}(nl)$, donde $n$ el el tamaño del grafo y $l$ el límite impuesto.

Este algoritmo puede trabajar partiendo desde cualquier clique, lo que nos permite utilizarlo en
técnicas híbridas como algoritmos meméticos, o combinarlo con el uso de un algoritmo \textit{greedy}
para tener una solución de partida prometedora. Para evaluar sus prestaciones por separado,
partirá desde un clique vacío, que es equivalente a pasarle una solución inicial construída
con un algoritmo \textit{greedy} que añada nodos utilizando el mismo criterio que esta búsqueda local.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{1LS}
  \begin{algorithmic}
  \Function{1LS}{clique, limite}
    \State $i = 0$
    \State $tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If {$C_0$ no es vacío}
        \State Añadir el nodo de $C_0$ que tenga más conexiones con $C_0$.
        \State $tabu = \emptyset$
      \Else
        \State Buscar en $C_1$ el primer intercambio que nos da un $C_0$ no vacío.
        \If {El intercambio existe}
          \State Hacer intercambio
          \State $tabu = \emptyset$
          \State $i = i + 1$
        \Else
          \State Quitar el nodo del clique con más adyacencias en el grafo.
          \State Añadirlo a $Tabu$.
          \State $i = i + 1$
        \EndIf
      \EndIf
      \State{Actualizar $C_0, C_1$, teniendo en cuenta $tabu$.}
    \Until{$i = limite$}
    \Return Mejor clique encontrado
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Dynamic Local Search}\label{dls}

Este algoritmo está basado en la búsqueda local dinámica o DLS (del inglés, \textit{Dynamic Local Search}),
propuesta por W. Pullan y H. Hoos \citep{pullan:2006}, y en concreto, se basa en una adaptación hecha
por A. Grosso, M. Locatelli y W. Pullan para un algoritmo de búsqueda local iterada \citep{grosso:2008},
que veremos más adelante. Sigue una filosofía más simple que el anterior, pues solo considera movimientos
\textit{add} y \textit{swap}, a los que volveremos a ordenar por prioridad. Además, incluye una
lista tabú con los nodos que han salido del clique mediante un swap, evitando que vuelvan a entrar
al clique y proporcionando diversidad.

Nuestro entorno consistirá en el conjunto de posibles adiciones ($C_0$) y el conjunto de
posibles intercambios ($C_1$), al que quitaremos la lista tabú. Como teóricamente, el entorno
puede ser vacío, si se diera el caso el algoritmo finalizaría. No obstante, se ha establecido
un límite de intercambios, pues en la práctica el entorno no tiene por qué ser vacío.

La prioridad entre movimientos es la siguiente: primero intentaremos añadir un elemento de
$C_0$ que no esté en la lista tabú, comprobando si existe alguno, y tomando uno aleatorio
en caso de existir varios. De no existir ninguno, tomaremos el conjunto $C_1$ y le quitaremos
la lista tabú. En caso de quedar algún nodo, haremos el intercambio, que volverá a ser aleatorio
si tenemos varios candidatos. Dicho nodo será añadido a la lista tabú para evitar que vuelva
a entrar al clique en las iteraciones más inmediatas. Finalmente, en caso de que este conjunto
también fuera vacío, solo nos queda la posibilidad de añadir un elemento de la lista tabú que
esté en $C_0$. Nuevamente, elegiremos uno aleatorio entre los existentes.

Este proceso se repetirá hasta que se satisfaga uno de los dos criterios de parada. Una vez
acabe el algoritmo, devolveremos el mejor clique que haya encontrado.

Como en este caso la elección de nodos es aleatoria, se considera un único bucle,
luego la complejidad de este algoritmo es lineal sobre el límite establecido,
$\mathcal{O}(l)$. Debido a esto, ofrecerá mejores tiempos de cómputo que el otro
algoritmo de búsqueda local implementado.

Este algoritmo también puede trabajar con cualquier clique de partida, siendo posible
utilizarlo como complemento a otras técnicas. Para evaluar su funcionamiento, tomaremos
como clique inicial un clique vacío, y dado el orden de prioridad de los movimientos,
el algoritmo creará un clique maximal de forma aleatoria y a partir de él explorará
su entorno.

Pasamos a ver el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{DLS}
  \begin{algorithmic}
    \Function{DLS}{clique, limite}
    \State $i = 0$
    \State $Tabu = \emptyset$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \If{$C_0 - Tabu$ no es vacío}
        \State Añadir un nodo aleatorio de $C_0 - Tabu$
      \ElsIf{$C_1 - Tabu$ no es vacío}
        \State Hacer un cambio con un nodo aleatorio de $C_1 - Tabu$.
        \State Añadir el nodo a la lista tabú que sale del clique a $Tabu$
        \State $i = i + 1$
      \ElsIf{$C_0$ es no vacío}
        \State Añadir un nodo aleatorio de $C_0$.
      \EndIf
      \State Actualizar $C_0, C_1$
      \State $entorno = C_0 \cup (C_1 - Tabu)$
    \Until{$i = limite$ o $entorno = \emptyset$}
    \Return Mejor clique encontrado
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Enfriamiento simulado}\label{enfriamiento}

El enfriamiento simulado es un algoritmo de búsqueda en entornos, que incluye un
criterio probabilístico de aceptación de soluciones basado en la termodinámica,
el algoritmo de Metrópolis. Fue introducido formalmente en 1983.

Su principal objetivo es evitar que la búsqueda en el entorno finalice en un óptimo
local, cosa que ocurre con la búsqueda local. Para esto, permitirá que algunos
movimientos vayan a soluciones peores, usando una función de probabilidad que decida
si se acepta un movimiento a una solución de menos calidad. Esta probabilidad vendrá
dada por el algoritmo de Metrópolis, e irá descendiendo a medida que avanza el algoritmo.
Así, conseguimos una diversificación de soluciones al principio, mientras que al final
del algoritmo intensificamos la búsqueda en una región concreta del espacio de soluciones.

El algoritmo de Metrópolis utiliza dos valores para calcular la probabilidad. Uno de ellos
es la diferencia entre los valores de la función objetivo de la solución del entorno y
la solución actual. El otro es un valor llamado temperatura, en referencia a su origen
termodinámico, que desciende en cada iteración de la búsqueda, lo que permitirá que
la probabilidad descienda con el valor.

Su forma de actuar es la siguiente: si nos movemos a una solución que mejore el resultado
anterior, la aceptamos directamente. De no ser así, calculamos la diferencia del valor de
la función objetivo, que notamos $\Delta F$, y tomamos como probabilidad de aceptación
$e^{\nicefrac{\Delta F}{T}}$, donde $T$ representa la temperatura. Como $\Delta F \leq 0$,
este valor estará siempre comprendido entre $0$ y $1$, siendo más cercano a $0$ cuanto
menor sean la temperatura y $\Delta F$.

El decrecimiento de la temperatura nos proporciona también un criterio de parada. Fijando
una temperatura final, usualmente cercana a $0$, el algoritmo se ejecutará hasta que la
temperatura alcance dicho valor. Así, conseguimos que la probabilidad de aceptación de
soluciones peores sea mayor al principio, favoreciendo la exploración, mientras que en
las fases finales la probabilidad de aceptación será baja, y el algoritmo intensificará
la búsqueda en la región del espacio de soluciones que se encuentre.

El descenso de la temperatura puede seguir distintos esquemas, aunque el más usual es el
geométrico, consistente en multiplicar la temperatura por una constante menor que $1$
en cada iteración. No obstante, cualquier función estrictamente decreciente nos resultaría
útil para realizar dicho descenso.

\subsection{Enfriamiento simulado en MCP}

El principal problema a la hora de elaborar un algoritmo de enfriamiento simulado en MCP
es la elección de una función objetivo que permita una exploración amplia del entorno.
Las funciones objetivo usuales, como el tamaño del clique, no aportan diversidad de soluciones,
pues una vez lleguemos a un óptimo local, normalmente repetirá movimientos de intercambio
de forma indefinida, ya que estos no cambian el valor de la función objetivo, y son
aceptados por el criterio de Metrópolis.

Establecer una prioridad entre los tres operadores de vecindad daría como resultado un
algoritmo muy similar a la búsqueda local, que seguiría teniendo los mismos problemas.
Por lo tanto, centraremos nuestro esfuerzo en buscar una función objetivo que nos
permita una mayor exploración. No obstante, hemos de tener en cuenta que el algoritmo
debe seguir convergiendo a un óptimo local, por lo que no nos vale cualquier función.

Es posible encontrar algunos trabajos sobre MCP que involucran el enfriamiento simulado.
Sin embargo, se suelen basar en una representación y una estructura diferentes a las
consideradas en este problema, siendo imposible trasladarlos completamente a este caso,
aunque sí pueden traerse algunas de las ideas principales. En el caso de este trabajo,
se ha implementado un algoritmo que utiliza las nociones básicas de enfriamiento simulado
para ver sus diferencias con la búsqueda local, y un segundo algoritmo que recoge algunas
ideas de un artículo sobre el problema.

\subsection{Primer algoritmo}\label{enfriamiento1}

Este algoritmo es una adaptación de una búsqueda local a un enfriamiento simulado, utilizando
una función objetivo basada en el tamaño de los cliques. En concreto, el valor de cada clique
es su tamaño más el número de vértices que contiene el conjunto $C_0$ dividido por el número
de vértices totales, que notaremos $N$.
\[ f(C) = |C| + \frac{|C_0|}{N} \]
De esta forma, conseguimos que cliques de mayor tamaño tengan siempre un valor mayor que
aquellos con menor tamaño, lo que garantiza la convergencia a un óptimo local. En caso
de empate, utilizamos el tamaño del conjunto $C_0$ para determinar el mejor, pues, como
hemos discutido con anterioridad, cuanto mayor sea $C_0$ más puede crecer el clique.

Para el entorno, he considerado movimientos \textit{add}, \textit{swap} y \textit{drop},
sin priorizar ninguno de ellos. Se tomarán en orden aleatorio hasta encontrar uno que
mejore la función objetivo o satisfaga el criterio de Metrópolis.

Los valores de temperatura han sido inicializados a $T_{\text{inicial}} = 1,
T_{\text{final}} = 0.001$, con un mecanismo de enfriamiento geométrico, consistente
en multiplicar la temperatura por una constante $\beta$, fijada a $\beta = 0.99$.
Una vez se alcance una temperatura menor que la final, completamos el mejor clique
encontrado añadiendo tantos nodos como sea posible (aunque lo más probable es que
no se añada ninguno), eligiendo dichos nodos por mayor número de adyacencias.
Finalmente, el algoritmo devuelve el clique y finaliza.

El algoritmo trabaja siempre partiendo del clique vacío. No obstante, puede ser
adaptado fácilmente para que comience la exploración desde cualquier clique, lo
que nos permitiría combinarlo con otros algoritmos para obtener técnicas híbridas.

Vemos una descripción del algoritmo en pseudocódigo.

\begin{algorithm}[H]
\caption{Enfriamiento Simulado}
  \begin{algorithmic}
    \Function{SA}{}
    \State $T = 1$
    \State $T_{\text{final}} = 0.001$
    \State $\beta = 0.99$
    \State Calcular $C_0$ y $C_1$.
    \Repeat
      \State Entorno = $C_0 \cup C_1 \cup$ Drops
      \Repeat
        \State Sacar un clique del entorno, calcular $\Delta F$.
        \If{$\Delta F \geq 0$}
          \State Aceptar solución.
          \State Salir del bucle interno.
        \Else
          \State Aceptar solución con probabilidad $e^{\nicefrac{\Delta F}{T}}$.
          \State Salir del bucle interno si se acepta la solución.
        \EndIf
      \Until{Entorno $= \emptyset$.}
      \State $T = T \times \beta$
    \Until{$T < T_{\text{final}}$}
    \State Ampliar mejor clique encontrado
    \Return mejor clique
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Segundo algoritmo}\label{enfriamiento2}

En el segundo algoritmo, se han adaptado las ideas de X. Geng, J. Xu, J. Xiao y L. Pan \citep{geng:2007},
que propusieron un algoritmo de enfriamiento simulado para MCP. Dicho algoritmo sigue
un enfoque distinto al de este problema, pues intenta buscar cliques de un tamaño
predeterminado, explorando el espacio de soluciones hasta que lo encuentra, o hasta
llegar al criterio de parada. Se basa en una representación por permutaciones del
vector de vértices, y va realizando intercambios de dos vértices, de tal forma que
uno sale del subgrafo y otro entra en él, siempre que la función objetivo mejore o
se satisfaga el criterio de Metrópolis. En este caso, en lugar de ir moviéndose entre
cliques, se consideran grafos de tamaño fijo, que se modificarán con el objetivo de
alcanzar un clique. Esto permite definir como función objetivo el número de aristas
que le faltan al grafo para ser un clique.

Para poder adaptarme a este enfoque, he tenido que diseñar un algoritmo que se moviera
entre grafos que no fueran necesariamente cliques. He utilizado los mismos tres operadores,
\textit{add, swap} y \textit{drop}, pero en este caso, he permitido añadir cualquier nodo
al grafo o intercambiar dos nodos cualesquiera, sin necesidad de que el resultado sea un clique.
La exploración del nuevo entorno se hace igual que en el caso anterior, de forma aleatoria.

Al principio tomé la mismo función objetivo que la propuesta por Geng et al., consistente
en el número de aristas necesarias para que el grafo sea un clique. Sin embargo, esta
función no asegura una convergencia a soluciones de calidad; en particular, es ajena al
tamaño de los cliques. Por esto, he usado la longitud de los grafos para corregir esta,
restándola al número de aristas restante. Así, tenemos una función objetivo que es menor
cuanto mayor es el grafo, y cuanto más se parece a un clique.

Una vez definida la función objetivo, el algoritmo explora el entorno y toma un elemento
aleatorio hasta que la función objetivo es menor, o hasta que se acepta el criterio de
Metrópolis. Como ahora no trabajamos con cliques, el grafo que obtenemos será reducido
a un clique, para lo que eliminaremos nodos uno a uno hasta que el resultado sea un clique.
Eliminaremos el nodo que menos adyacencias tenga. El clique obtenido no sustituye al grafo
que tengamos, sino que se compara con el mejor clique obtenido hasta el momento, reemplazándolo
si su longitud fuera mayor. Después del algoritmo continua explorando el entorno del
grafo actual, repitiendo el método descrito.

He vuelto a tomar los valores $T_{\text{inicial}} = 1, T_{\text{final}} = 0.001,
\beta = 0.99$ para los parámetros del algoritmo. Una vez finaliza la fase de enfriamiento,
vuelvo a añadir tantos nodos como sea posible al mejor clique encontrado, mediante un algoritmo
\textit{greedy} que prioriza los nodos con más adyacencias, devolviendo el clique resultante.

Dado que la principal diferencia con el anterior algoritmo son el espacio de
búsqueda,  y la función objetivo, no se incluye pseudocódigo de este algoritmo,
por ser similar al anterior.


\section{Búsquedas multiarranque}

Las búsquedas multiarranque son un tipo de búsqueda local, que intentar salir de óptimos
locales reiniciando la búsqueda para tomar otra solución de partida, buscando explorar
una región distinta del espacio de soluciones. Dicha reinicialización de la búsqueda será
la clave para distinguir entre búsquedas multiarranque, y podemos clasificarlas como sigue:

\begin{itemize}
  \item Búsqueda multiarranque básica, que genera una solución inicial aleatoria y explora su entorno
        mediante búsqueda local, repitiendo el proceso hasta que se satisfaga una condición de parada.
        Es el método más sencillo, que no utiliza ningún tipo de información del problema, y equivale
        a aplicar una búsqueda local múltiples veces sobre distintas soluciones aleatorias de partida.

  \item Métodos constructivos de la solución inicial, donde esta varía en cada iteración. En este caso,
        la solución inicial se obtiene mediante una construcción, intentando conseguir soluciones de
        partida que sean de calidad. Intentaremos que las soluciones sean distintas en cada iteración,
        por lo que el proceso de construcción será usualmente aleatorizado. Una vez se tenga la solución
        inicial, se aplica búsqueda local, repitiendo hasta satisfacer una condición de parada,
        normalmente un número de iteraciones fijo de antemano.

  \item Métodos basados en la modificación del óptimo encontrado, en los que el óptimo local se somete
        a una perturbación, dando lugar a una nueva solución de partida. Con esto utilizamos una
        solución ya calculada para proporcionar una nueva solución de partida, con la que intentaremos
        mejorar la calidad de la solución anterior. Nuevamente, repetiremos el proceso hasta alcanzar
        una condición, que habitualmente será un número de repeticiones dado.
\end{itemize}

En este trabajo he considerado dos tipos de algoritmos multiarranque; algoritmos GRASP
(\textit{Greedy Randomized Adaptative Search Procedure}), basados en la construcción
de la solución inicial, y algoritmos ILS (\textit{Iterated Local Search}), basados
en modificaciones de la solución encontrada. Vamos a detallarlos.

\subsection{GRASP}\label{grasp}

El algoritmo GRASP \citep{feo:1995}, o \textit{greedy} aleatorizado, es un algoritmo
multiarranque que consiste en repetir una fase de construcción de una solución,
seguida de una búsqueda local en el entorno de dicha solución, hasta que se alcance
una condición, que suele ser un límite de iteraciones o de tiempo de ejecución.
Es un algoritmo sencillo de programar, y su capacidad para obtener buenas soluciones
está ligada a si los algoritmos \textit{greedy} y la búsqueda local ofrecen buenos
resultados sobre el problema, pues está fundamentado en ellos. Fue usado por primera
vez en 1989 por T. A. Feo y M. G. C. Resende \citep{feo:1989}, aunque la idea había
sido descrita en 1987 por J. P. Hart y A. W. Shogan \citep{hart:1987}.

La construcción de la solución inicial sigue un procedimiento \textit{greedy}, en el cual,
en lugar de proporcionar un único candidato como se haría en un algoritmo \textit{greedy}
clásico, se proporciona una lista restringida de candidatos (RCL), que es un conjunto
de los mejores candidato, tomados de entre todos los posibles, y de entre estos,
elegiremos uno al azar. El tamaño de RCL es un parámetro, que dependiendo de su valor
hace a la construcción más similar a un \textit{greedy} o a un algoritmo aleatorio,
pues notemos que si el número de candidatos es $1$, el algoritmo será un \textit{greedy}
puro, mientras que si es el tamaño de la lista de candidatos, el algoritmo será aleatorio \citep{herrera:2014}.

Esta técnica se utiliza para proporcionar diversidad, pues esta se pierde al tomar soluciones
iniciales generadas por algoritmos voraces. Así, seguimos obteniendo buenas soluciones de
partida, a la vez que estas difieren lo suficiente como para explorar una región amplia del
espacio de soluciones.

Una vez construída la solución inicial, se explora su entorno siguiendo una búsqueda local,
hasta alcanzar un óptimo local. Una vez alcanzado, se compara la solución con la mejor obtenida
hasta el momento, se actualiza si es necesario, y se comienza de nuevo el algoritmo.
Se repetirá el proceso hasta satisfacer una condición de parada.

\subsubsection{GRASP en MCP}

El aspecto fundamental de este algoritmo es la construcción de la solución inicial.
Podemos valorar los elementos del conjunto de candidatos de distintas formas, lo que
dará lugar a distintas soluciones de partida. Por lo demás, el algoritmo se basa en
una búsqueda local, que hemos discutido con anterioridad.

\subsubsection{Algoritmo implementado}

Como se acaba de mencionar, el aspecto fundamental de este algoritmo es la generación de
la solución inicial. Para ello, he tomado la lista de candidatos, $C_0$, y la he ordenado
por número de adyacencias en el grafo, en orden descendente. Una vez ordenada, tomo la
mitad superior como conjunto de candidatos, y hago una elección aleatoria entre los nodos,
en la que todos tienen la misma probabilidad de ser elegidos. El proceso se repetirá hasta
que $C_0$ sea vacío.

La fase de búsqueda local utiliza los dos métodos ya implementados, 1LS y DLS, lo que da lugar a
dos versiones del algoritmo, en las que solo varía la búsqueda local. Como estos métodos
no se detienen en un óptimo, sino que necesitan un número de iteraciones máximo, he
establecido como límite el número de vértices del grafo, para que se adapte al tamaño
de cada problema.

Este proceso se repetirá un número determinado de iteraciones, que se pasará como parámetro.
Para este caso se ha fijado a $20$ en todas las instancias disponibles. Almacenaremos la
mejor solución obtenida, que será la que el algoritmo devuelva al final.

Vemos el pseudocódigo del algoritmo y de la generación de soluciones iniciales.

\begin{algorithm}[H]
\caption{GRASP}
  \begin{algorithmic}
  \Function{GRASP}{limite}
    \State $i = 0$
  \Repeat
    \State Obtener solución inicial.
    \State Aplicar búsqueda local a la solución inicial.
    \State Actualizar mejor solución.
    \State $i = i+1$
  \Until{$i = limite$}
  \Return mejor clique
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Generación de soluciones aleatorias}
  \begin{algorithmic}
    \State $clique = \emptyset$
    \State $C_0 =$ vértices
    \Repeat
      \State Ordenar $C_0$ por adyacencias.
      \State Tomar la mitad superior de $C_0$.
      \State Añadir un elemento aleatorio a $clique$.
      \State Recalcular $C_0$.
    \Until{$C_0 = \emptyset$}
    \Return $clique$
  \end{algorithmic}
\end{algorithm}


\subsection{ILS}\label{ils}

La búsqueda local iterada, o ILS (del inglés, \textit{Iterated Local Search}), es
un algoritmo de búsqueda local multiarranque basado en la perturbación de soluciones
como método para obtener diversidad. Fue propuesta en 1998 por Thomas Stützle en
su tesis doctoral \citep{stuztle:1998}, y desde entonces se utiliza en la resolución
de distintos problemas, entre los que se encuentra el problema del clique máximo.

El algoritmo ILS requiere de cuatro componentes principales: una solución inicial,
un algoritmo de mutación de soluciones, un método de búsqueda local, y un criterio
de aceptación. Definiendo estos cuatro componentes en un problema, estaremos en
condiciones de aplicar el algoritmo.

El funcionamiento general de este tipo de algoritmos es el siguiente: primero, se
toma la solución inicial y se le aplica búsqueda local, hasta llegar a un óptimo local.
Seguidamente, se le aplica una mutación a la solución obtenida, que nos permite crear
una nueva solución inicial a la que volver a aplicar búsqueda local. Una vez finalizada
esta segunda búsqueda local, se usa el criterio de aceptación para ver si reemplazamos
la solución anterior con la obtenida. Este proceso mutación-búsqueda local-aceptación
se repetirá hasta que se satisfaga un criterio de parada. Finalmente, el algoritmo
devuelve la mejor solución encontrada.

Este modelo de ILS es el más básico que existe, pero no es el único. Podemos utilizar
un modelo basado en poblaciones, donde a cada elemento se le aplica ILS y estos se
combinan de alguna forma para una mayor exploración del espacio de soluciones, o el
modelo $(\nu + \lambda)$, donde, partiendo de $\nu$ soluciones iniciales, generamos
$\lambda$ hijos a partir de ellas mediante mutación, que compiten para pasar a la siguiente fase.

También es posible establecer diferencias en el criterio de aceptación. Si bien el
método más usual es tener una función objetivo, pueden utilizarse otros, como una
selección aleatoria, una selección basada en combinaciones, o una basada en probabilidades,
en la que podría utilizarse el algoritmo de Metrópolis, por ejemplo.

La magnitud de la perturbación aplicada es muy importante a la hora de obtener
buenos algoritmos. Una perturbación demasiado débil podría hacernos caer en los
mismos óptimos locales de forma sucesiva, mientras que una perturbación demasiado
fuerte nos haría perder información de la solución y actuaría de forma similar a
un reinicio aleatorio \citep{herrera:2014}.

\subsubsection{ILS en MCP}

Es sencillo construir una búsqueda local iterada para el problema del clique máximo,
partiendo de un algoritmo de búsqueda local existente. Para ello, son necesarios un
criterio de aceptación, una solución inicial y una función de mutación.

\subsubsection{Algoritmo implementado}

Se ha implementado un algoritmo que sigue la filosofía de la búsqueda local iterada
básica basado en el propuesto por A. Grosso, M. Locatelli y W. Pullan \citep{grosso:2008},
que usa el algoritmo de búsqueda local DLS \citep{pullan:2006}, si bien se propusieron
algunas modificaciones que aquí no se han tenido en cuenta. Además de DLS he utilizado
1LS, aprovechando que ya estaba implementado. Esto nos da dos algoritmos ILS distintos,
que difieren únicamente en la búsqueda local.

Vemos a continuación la función de mutación y el criterio de aceptación utilizados.

El algoritmo para mutar un clique consiste en tomar un nodo que no se encuentre en él,
eliminar del clique todos los nodos que no estén conectados a él, y finalmente añadir
dicho nodo al clique. Con este método conseguimos una solución de partida que se encuentra
en una zona distinta del espacio de soluciones, a la vez que usamos información de la
iteración anterior para movernos por soluciones que serán potencialemente de calidad.

La función de aceptación se queda siempre con el último clique obtenido tras la búsqueda local.
Tras valorar si quedarme con la última o con la mejor encontrada, decidí hacer lo primero,
para favorecer la diversidad en las soluciones. No obstante, tendremos almacenada la mejor
solución, al ser el valor de salida del programa.

Dado que las dos búsquedas locales implementadas requieren de un límite como criterio de
parada, he fijado dicho límite al número de vértices del grafo, para que se adapte al
tamaño de cada problema. Además, el criterio de parada del algoritmo también es un número
de iteraciones, que ha sido $20$ para todas las instancias.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ILS}
  \begin{algorithmic}
  \Function{ILS}{}
    \State Generar solución inicial.
    \State Aplicar búsqueda local.
    \Repeat
      \State Modificar solución.
      \State Aplicar búsqueda local a la solución obtenida.
      \State Actualizar la mejor solución, si es necesario.
    \Until{Se alcance el número de iteraciones.}
    \Return mejor solución obtenida
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Algoritmos de colonia de hormigas}\label{aco}

Los \textbf{algoritmos de colonia de hormigas} \citep{dorigo:1996} o ACO
(del inglés, \textit{Ant Colony Optimization}) son una técnica de adaptación social,
que se basa en el comportamiento de las colonias de hormigas, para tratar de encontrar
caminos en grafos. Para ello, utilizará un recurso que emula a las feromonas que
emiten las hormigas cuando se desplazan.

Las hormigas utilizan este rastro de feromonas para guiarse, pues poseen unos receptores
capaces de captar la intensidad de dicho rastro. Dado su pésimo sentido de la vista,
el uso de las feromonas es vital para que las hormigas se desplacen y sean capaces de
localizar fuentes de alimento, volver al hormiguero, y que el resto de la colonia también
sea capaz de llegar a la comida, siguiendo el rastro que las propia hormigas dejan.

Este rastro de feromonas no permanece de forma indefinida en el ambiente, sino que
sufre un proceso de evaporación constante. De esta forma, caminos más cortos tenderán
a una mayor concentración de feromonas, lo que incrementará el tránsito de hormigas.
Por otra parte, los caminos más largos recibiran menos aporte de feromonas, lo que a
la larga hará que dejen de ser visitados.

La elección por parte de una hormiga del camino que recorrer se fundamenta en un
criterio probabilístico. La hormiga tiende a recorrer caminos en los que el rastro
de feromona es mayor, aunque podrá ir por otros donde el rastro no sea tan intenso.

Su fundamentación teórica hace que sea un algoritmo muy eficaz para problemas que
requieren de construcción de caminos, como el problema del viajante de comercio.
En general, son algoritmos que funcionan bien cuando trabajan sobre estructuras
similares a los grafos.

Este comportamiento será trasladado a la optimización por colonia de hormigas,
mediante la construcción de hormigas artificiales. Tendremos un rastro de feromona
artificial, que simula el que dejan las hormigas al recorrer un camino. Es posible
complementar el uso de las feromonas con información heurística del problema,
con el objetivo de crear un mecanismo probabilistico de construcción de soluciones
que no solo se base en feromonas, sino que use más información disponible.

Las hormigas construirán un camino de forma incremental utilizando la información
de la que disponen, comenzando desde un nodo aleatorio y eligiendo el siguiente
mediante una función de probabilidad, que depende de los valores de feromona.

Los nodos que compongan una solución serán reforzados con un aumento de feromonas, y
se hará de forma que mejores soluciones reciban más cantidad de feromona.
Se utiliza también un mecanismo de evaporación de feromona simulando el que ocurre en
la naturaleza, que evita un crecimiento ilimitado de la misma. Para esto, se reducirán
todos los rastros de feromona eliminando un parte de su valor actual, usualmente un
porcentaje fijo. En la práctica, esto se traduce en evitar un estancamiento del algoritmo,
debido a que los nodos más visitados tendrían altas probabilidades de repetirse en la
siguiente solución.

Se lanzarán un número determinado de hormigas artificiales independientes, las
cuales generan una solución cada una. Entre ellas, se toma la mejor, y esta será la
que cambie los niveles de feromona. Este proceso se repite hasta que se satisfaga una
condición de parada, que suele ser un número de iteraciones o un límite temporal.

Existen numerosas variantes de las colonias de hormigas, dependiendo de la función de
probabilidad, la actualización de feromonas, etcétera. En este trabajo he tomado el
algoritmo más clásico, sin entrar en otros que requerirían de mayor experimentación
para hacer ajustes sobre los parámetros. También es posible hibridar este método
con otros, usualmente un algoritmo de búsqueda basado en entornos, como una búsqueda
local o un enfriamiento simulado.

\subsection{ACO en MCP}

Al ser el problema del clique máximo un problema de grafos, los algoritmos de colonias
de hormigas son fácilmente implementables, ya que adaptar el problema a una búsqueda
de caminos en grafos es directo. Trabajaremos con conjuntos de candidatos sobre los
cuales podremos una acción, como un \textit{add} o un \textit{swap}.

En este trabajo, he considerado dos algoritmos de colonias de hormigas clásicos,
lanzando una colonia de hormigas durante un número determinado de iteraciones y
reforzando el nivel de feromonas en las soluciones de calidad. La evaporación se
realiza reduciendo un porcentaje de feromona, fijo en todas las iteraciones.
La diferencia entre ambos algoritmos reside en la función de probabilidad;
mientras que uno de ellos utiliza solo las feromonas, el segundo complementa
el uso de las feromonas con información del grafo.

\subsection{ACO básico}\label{aco1}

El primer algoritmo es una implementación propia, consistente en una colonia de
hormigas de tamaño fijo, y en la que las hormigas crean una solución cada una,
siendo la mejor la que se tiene en cuenta para modificar los niveles de feromona.
He considerado únicamente movimientos \textit{add}, por lo que las hormigas irán
recorriendo los nodos del conjunto $C_0$ hasta que este sea vacío.

Cada hormiga comenzará desde un clique vacío y añadirá nodos del conjunto $C_0$ según
una regla probabilística, que consiste en dar a cada nodo del conjunto una probabilidad
proporcional a su feromona, normalizándola para obtener un valor entre $0$ y $1$, y
conseguir que la suma de todas las probabilidades de los nodos de $C_0$ sea $1$.
Para ello,  solo hemos de dividir el valor de la feromona de un nodo por la suma de
los valores de los nodos de $C_0$. Inicialmente, la probabilidad será la misma para
cada nodo,  por lo que no damos ventaja a ninguno y dejamos que sea el proceso el
que determine los mejores nodos.

El proceso se repite hasta que la hormiga finaliza la creación de su clique, dando
paso a la siguiente, que crea uno distinto, y así hasta que todas las hormigas completen
el suyo. Cada vez que una hormiga finaliza, compara su clique con el mejor obtenido
en esa iteración, sustituyéndolo de ser necesario. Así, tendremos siempre el mejor
clique creado por la colonia a lo largo de cada iteración.

Una vez finalizado el trabajo de todas las hormigas, se produce la evaporación de
feromona, consistente en multiplicar los valores en cada nodo por una constante $\beta$.
Seguidamente, se aumentan los niveles de feromona en los nodos de la mejor solución,
multiplicando el valor de esta por un valor $\alpha$. Este valor dependerá del tamaño
del clique encontrado, siendo mayor cuanto más tamaño tiene el clique. Así, conseguimos
dar más peso a soluciones de más calidad.

El proceso se repite un número fijado de iteraciones. Una vez terminadas todas las
iteraciones, el algoritmo finaliza y devuelve la mejor solución encontrada.

Se han fijado los valores $\beta = 0.925$, $\alpha = (5 \times |C| + N) / N$, donde
$|C|$ es el tamaño del clique encontrado, y $N$ es el número de vértices del grafo.
Para fijarlos, me he valido de la experimentación en instancias pequeñas del problema,
tomando aquellos que daban mejores resultados. No obstante, las diferencias eran
mínimas entre todos los valores probados. El número de hormigas en cada iteración
ha sido fijado a $50$, efectuándose un total de $40$ iteraciones.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{ACO básico}
  \begin{algorithmic}
  \Function{ACO}{limite, limite hormigas}
    \State $T_{\text{final}} = 0.01$
    \State Inicializar constantes $\alpha, \beta$.
    \State $Mejor Clique = []$.
    \Repeat
      \State $Hormigas = 0$.
      \State Establecer el mejor clique de la colonia al clique vacío.
      \Repeat
        \State $Clique = []$
        \State Añadir vértice aleatorio al clique
        \State Calcular $C_0$
        \Repeat
          \State Calcular probabilidades de los nodos en $C_0$. Normalizar.
          \State Elegir un nodo según la probabilidad y añadirlo a clique.
          \State Recalcular $C_0$.
        \Until{$C_0 = \emptyset$}
        \State Actualizar el mejor clique de la colonia si es necesario.
        \State $Hormigas = Hormigas + 1$.
      \Until{$Hormigas = límite hormigas$}
      \State Actualizar $Mejor Clique$ si es necesario.
      \State Evaporar feromona.
      \State Aportar feromona a los nodos del mejor clique de la colonia.
      \State $i = i+1$.
    \Until{$i = limite$}
    \Return{mejor clique}
  \EndFunction
  \end{algorithmic}
\end{algorithm}


\subsection{ACO con enfriamiento simulado}\label{aco-sa}

Este algoritmo toma algunas de las ideas de X. Xu, J. Ma y J. Lei \citep{xu:2007},
que trata de mejorar el ACO básico considerando información relativa al clique
para calcular las probabilidades de elegir un nodo. La única diferencia con el
anterior está dicho cálculo, para el que utilizaremos una técnica de enfriamiento
simulado, además del uso de los valores de feromona.

La probabilidad de cada nodo se compone de dos partes: la primera de ellas es idéntica
a la anterior, un valor entre $0$ y $1$ obtenido de las feromonas de cada nodo en $C_0$
normalizada, para que la suma total sea $1$. Además, sumaremos un valor que depende
del grado de cada nodo, y estará multiplicado por una temperatura, de forma que la
importancia de este término desciende en el tiempo. La fórmula para el cálculo
de la probabilidad queda de la siguiente forma:
\[ p(v_i) = \frac{\tau(v_i)}{\sum\limits_{v_j \in C_0} \tau(v_j)} + T \frac{D(v_i)}{N} \]
donde $\tau(v_i)$ es el valor de la feromona en el nodo $v_i$, $T$ es la temperatura,
$N$ el número de nodos del grafo, y $D(v_i)$ es el grado de $v_i$. Una vez calculadas
todas las probabilidades de los nodos de $C_0$, volveremos a normalizarlas, para tener
valores entre $0$ y $1$ y que la suma siga siendo $1$.

La temperatura sigue un esquema de descenso geométrico similar al utilizado en
\autoref{enfriamiento1} y \autoref{enfriamiento2}, en los que la temperatura se multiplica
por una constante $\gamma$ en cada iteración, tomando $\gamma = 0.95$. Los valores
de $\alpha$ y $\beta$ siguen siendo los mismos que en el algoritmo anterior, al
igual que el número de hormigas y de iteraciones, que son $50$ y $40$ respectivamente.

Puesto que solo cambia la función del cálculo de la probabilidad, no incluyo pseudocódigo
de este algoritmo, por ser similar al anterior.

\section{Algoritmos genéticos}\label{genetico}

Los algoritmos genéticos entran dentro de la llamada \textbf{computación evolutiva},
que está compuesta por modelos de evolución basados en poblaciones. Se basan en
los procesos evolutivos presentes en la naturaleza, en los que dos padres combinan
sus genes para producir hijos, los cuales presentan características de ambos.
Las diferencias entre generaciones pueden llevar a nuevas configuraciones que
devengan en una mejor adaptación al entorno. Esto, en el ámbito que nos encontramos,
se traduce en cambios que nos lleven mejores soluciones, pues estas se adaptan
mejor al problema \citep{herrera:2014}.

En los algoritmos genéticos, las poblaciones estarán formadas por soluciones al
problema, que combinaremos dos a dos para producir descendientes que intenten mejorar
a sus progenitores. Esta combinación de soluciones se produce mediante el llamado
\textbf{operador de cruce}, que emula cómo los cromosomas se mezclan para producir
una nueva generación, y cuyo requisito fundamental es que se tome información de
ambos progenitores para crear a sus descendientes.

En la naturaleza, es posible que al combinar dos individuos se produzca una mutación,
con lo cual el hijo tendría una característica que no ha adquirido de ninguno de sus
padres, y que podría conllevar una ventaja o un perjuicio para el mismo. Esta técnica
se reproducirá en los algoritmos genéticos, incluyendo la posibilidad de que una
solución mute al ser generada. Al igual que el operador de cruce, las mutaciones
pueden seguir distintos enfoques, aunque se suele requerir que introduzcan modificaciones
significativas en los elementos de la población.

Controlaremos el cruce entre individuos y las mutaciones de sus descendientes con
parámetros que establezcan la probabilidad de que ambos sucesos ocurran. Para el
cruce, seleccionaremos dos individuos que o bien generarán descendientes, o bien
pasarán directamente a la siguiente generación. En caso de generar descendientes,
cada uno de ellos podrá ser mutado en el momento de su creación.

Existen distintas formas de seleccionar a los padres. El muestreo puede ser aleatorio,
se puede dar mayor probabilidad de combinarse a los mejores, etc. No hay restricción
en cuanto al número de veces que se puede reproducir un elemento, si bien podría
establecerse de considerarse necesario.

De igual forma, existen diversos métodos para crear una nueva generación. Una de
ellas sería que los hijos sustituyan a los padres, el llamado modelo \textit{generacional}.
En este caso, se crea una nueva población en cada iteración del ciclo. Es posible
incluir elitismo, de forma que la mejor solución de la población pasa siempre a
la siguiente generación, lo que nos permite conservarla siempre sin necesidad de
almacenarla explícitamente. Otro modelo es el llamado \textit{estacionario}, en
el cual se eligen dos padres, que generan dos hijos, y estos compiten para pasar a la
siguiente generación, pudiendo hacerlo con los padres o con la población en general.
Este modelo ya es elitista, luego no necesita introducir elitismo explícitamente.

\subsection{Genéticos en MCP}

Implementar un algoritmo genético para el problema del clique máximo se basa en
considerar operadores de cruce y mutación apropiados, esto es, que mantengan la
estructura de clique. A priori, no podemos afirmar que la combinación arbitraria
de dos soluciones o la mutación produzcan cliques, por lo que estos operadores
deben ser muy específicos o ser rectificados de alguna forma.

Una vez tengamos estos operadores, la ejecución del algoritmo consiste simplemente
en ir obteniendo nuevas generaciones hasta un criterio de parada determinado.
En este caso, para el algoritmo implementado, se ha establecido un número fijo de
iteraciones.

\subsection{Algoritmo implementado}\label{alg-genetico}

El algoritmo genético implementado se basa en las ideas de S. Zhang, J. Wang, Q. Wu
y J.Zhan \citep{zhang:2014}, que usa un modelo estacionario, en el que los dos
descendientes compiten con sus padres para entrar en la nueva generación.
Al principio, se creará una población de soluciones de forma aleatoria mediante
un algoritmo \textit{greedy}, y a partir de aquí se irán generando nuevas soluciones.

El operador de cruce opera de la siguiente forma: dados dos padres, se toman aquellos
nodos comunes en ambos, y estos estarán presentes en ambos hijos. Seguidamente,
tomaremos el conjunto de nodos presentes en uno de los dos padres, y los distribuiremos
entre los dos hijos de forma aleatoria y equiprobable.

Una vez tengamos los hijos, procedemos a mutarlos con la probabilidad dada. El
algoritmo de mutación toma dos valores aleatorios entre $0$ y el número de nodos
del grafo, y cambia los nodos del intervalo que forman, quitándolos del hijo si
pertenecen a él, e introduciéndolos si no lo hacen.

Como no tenemos garantizado que los hijos sean cliques antes o después de la mutación,
los reduciremos a un clique eliminando nodos hasta que el conjunto restante sea un
clique. Una vez reducido, lo ampliaremos hasta que el clique sea maximal.
Ambos procesos de reducción y ampliación se hacen de forma aleatoria, si bien
podríamos haber tomado cualquier otro método basado en el información del grafo,
como ordenar por número de adyacencias.

La población inicial se ha tomado con un tamaño de $50$ individuos, con probabilidad
de cruce de $1$ y probabilidad de mutación de $0.1$, un valor alto para lo usual,
fijado así para introducir diversidad en la población. El criterio de parada es un
límite de iteraciones, que se ha fijado a $40$ en las ejecuciones realizadas.
Estos parámetros pueden ser modificados para evaluar la funcionalidad del algoritmo
bajo otras circunstancias.

Vemos el pseudocódigo del algoritmo:

\begin{algorithm}[H]
\caption{Genético}
  \begin{algorithmic}
  \Function{genetico}{iteraciones}
    \State $P_{mutación} = 0.1$.
    \State $P_{cruce} = 1$.
    \State Crear población inicial aleatoria.
    \State Mejor clique = mejor clique de la población.
    \Repeat
      \State $Nueva\_población = []$.
      \Repeat
        \State Extraer dos elementos aleatorios de la población.
        \State Cruzar los dos elementos con probabilidad $P_{cruce}$.
        \State Mutar primer hijo con probabilidad $P_{mutación}$.
        \State Mutar segundo hijo con probabilidad $P_{mutación}$.
        \State Reparar y completar primer hijo.
        \State Reparar y completar segundo hijo.
        \State Añadir los dos hijos a $Nueva\_población$.
      \Until{$Poblacion = \emptyset$}
      \State $Población = Nueva\_población$.
      \State Actualizar mejor clique.
    \Until{$i = iteraciones$}
    \Return{mejor clique}
  \EndFunction
  \end{algorithmic}
\end{algorithm}


\section{Algoritmos meméticos}\label{memeticos}

Los algoritmos meméticos son el resultado de la combinación de algoritmos meméticos
con búsqueda local. Tratan de aprovechar la buena capacidad de exploración de los
algoritmos genéticos, y combinarla con la explotación de soluciones de las técnicas
de búsqueda local.

El diseño de estos algoritmos queda muy abierto, y por lo general, suele ser necesario
adaptarlos de una forma u otra dependiendo del problema. Suelen ser algoritmos específicos,
que aprovechan alguna característica en concreto del problema.

Entre las diversas decisiones que hay que tomar, una de las más relevantes es el
proceso de búsqueda local a considerar y cuándo aplicarlo. Podemos elegir cualquier
técnica por trayectorias simples, desde una búsqueda local básica a una busqueda
tabú, y podemos aplicarlas a toda la población o a una parte, en distintas
fases del algoritmo.

\subsection{Meméticos en MCP}

Debido a que disponemos de técnicas de búsqueda local y un algoritmo genético, la
implementación de un algoritmo memético consiste en tomar las decisiones correspondientes
con respecto a la hibridación de ambas técnicas.

\subsection{Algoritmo implementado}\label{alg-memetico}

En este trabajo, he optado por una combinación básica de dos algoritmos ya implementados,
el algoritmo genético anterior y DLS como búsqueda local. De esta forma, se mantiene
la estructura de algoritmo genético estacionario, introduciendo una búsqueda local
al final de la creación de la nueva generación, lo que nos permite explorar su entorno
antes de pasar a la siguiente.

El desarrollo del algoritmo es muy simple, pues utiliza como base el algoritmo
genético introducido anteriormente. Utiliza el mismo operador de cruce y mutación,
y añade una búsqueda local después de que los hijos sean reducidos y ampliados.

He utilizado DLS y no 1LS debido a su menor complejidad computacional, pues hibridar
con 1LS producía tiempos de ejecución demasiado elevados.

Como parámetros, he tomado las mismas probabilidades de cruce y mutación, $1$ y $0.1$,
y he establecido el límite de la búsqueda local en un octavo del número de nodos
del grafo, para explorar únicamente la zona del espacio de soluciones más cercana
a cada elemento de la población.
